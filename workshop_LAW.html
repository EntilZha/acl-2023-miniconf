


<!DOCTYPE html>
<html lang="en">

<head>
  
  <!-- Required meta tags -->
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />


  <!-- External Javascript libs  -->
  <script src="https://cdn.jsdelivr.net/npm/d3@5/dist/d3.min.js"></script>

  <script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js"
    integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script>

  <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"
    integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>

  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
    integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
    crossorigin="anonymous"></script>


  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js"
    integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script>

  <script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js"
    integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script>

  <script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js"
    integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script>

  <!-- https://developer.snapappointments.com/bootstrap-select/ -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-select@1.13.14/dist/css/bootstrap-select.min.css">
  <script src="https://cdn.jsdelivr.net/npm/bootstrap-select@1.13.14/dist/js/bootstrap-select.min.js"></script>

  <!-- Library libs -->
  <script src="static/js/typeahead.bundle.js"></script>

  <script src="https://craig.global.ssl.fastly.net/js/mousetrap/mousetrap.min.js?a4098"></script>

  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.0/css/all.css"
    integrity="sha384-lZN37f5QGtY3VHgisS14W3ExzMWZxybE1SJSEsQp9S+oqd12jhcu+A56Ebc1zFSJ" crossorigin="anonymous">

  <!-- External CSS -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css"
    integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous">

  <!-- External Fonts (no google for china) -->
  <link href="static/css/Lato.css" rel="stylesheet" />
  <link href="static/css/Exo.css" rel="stylesheet" />
  <link href="static/css/Cuprum.css" rel="stylesheet" />

  <link rel="stylesheet" href="static/css/main.css" />
  <link rel="stylesheet" href="static/css/chats-modal.css" />
  <link rel="stylesheet" href="static/css/lazy_load.css" />
  <link rel="stylesheet" href="static/css/typeahead.css" />
  <script src="https://cdn.jsdelivr.net/npm/pdfjs-dist@2.3.200/build/pdf.min.js"></script>
  <script src="static/js/pdf_render.js"></script>

  <title>ACL2023: LAW</title>
  

  <!-- Favicon -->
  <link rel="apple-touch-icon" sizes="180x180" href="static/favicon/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="static/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="static/favicon/favicon-16x16.png">
  <link rel="manifest" href="static/favicon/site.webmanifest">
  <link rel="mask-icon" href="static/favicon/safari-pinned-tab.svg" color="#5bbad5">
  <link rel="shortcut icon" href="static/favicon/favicon.ico">
  <meta name="msapplication-TileColor" content="#2d89ef">
  <meta name="msapplication-config" content="static/favicon/browserconfig.xml">
  <meta name="theme-color" content="#ffffff">
</head>

<body>
  <!-- NAV -->
  
  <!-- ('https://2023.aclweb.org/faq/', 'FAQ'), -->
  <!-- ('https://2023.aclweb.org/committees/organization/', 'Organizers'), -->
  <!-- ('https://2023.aclweb.org/sponsors/', 'Sponsors') -->

  <!-- Add back ('livestream.html', 'Livestream'),
    ('about.html', 'Help'),
    ('plenary_sessions.html', 'Plenary'),
    ('livestream.html', 'Livestream'),
    (config.gather_town , 'Gather'),
    for a new conference
    -->

  <nav class="navbar sticky-top navbar-expand-lg navbar-light  bg-emnlp mr-auto customnav" id="main-nav">
    <div class="container">
      <a class="navbar-brand" href="index.html">
        <img class="logo" src="static/images/acl2023/acl-logo-2023.png" height="45px"
          width="auto" alt="ACL 2023" />
      </a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav"
        aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
        <ul class="navbar-nav ml-auto">
          
          <li class="nav-item ">
            
            <a class="nav-link" href="index.html">Home</a>
            
          </li>
          
          <li class="nav-item ">
            
            <a class="nav-link" href="schedule.html">Schedule</a>
            
          </li>
          
          <li class="nav-item ">
            
            <a class="nav-link" href="sessions.html">Sessions</a>
            
          </li>
          
          <li class="nav-item ">
            
            <a class="nav-link" href="papers.html">Papers</a>
            
          </li>
          
          <li class="nav-item ">
            
            <a class="nav-link" href="tutorials.html">Tutorials</a>
            
          </li>
          
          <li class="nav-item ">
            
            <a class="nav-link" href="workshops.html">Workshops</a>
            
          </li>
          
          <li class="nav-item ">
            
            <a class="nav-link" href="map.html">Map</a>
            
          </li>
          
          <li class="nav-item ">
            
            <a class="nav-link" href="https://acl.rocket.chat" target="_blank"><u>Chat</u></a>
            
          </li>
          
          <li class="nav-item ">
            
            <a class="nav-link" href="https://app.gather.town/app/5OscLswEEuYf2Psb/ACL2023" target="_blank"><u>GatherTown</u></a>
            
          </li>
          
          <li class="nav-item ">
            
            <a class="nav-link" href="https://2023.aclweb.org/" target="_blank"><u>Main Site</u></a>
            
          </li>
          
          <li class="nav-item ">
            
            <a class="nav-link" href="https://2023.aclweb.org/downloads/acl2023-handbook.pdf" target="_blank"><u>Handbook</u></a>
            
          </li>
          
        </ul>
      </div>
    </div>
  </nav>
  

  
  <!-- User Overrides -->
   

      
      <div class="container">
        
    <!-- Heading -->
    <div class="heading">
       
    </div>
    <div class="tabs pt-3">
      <!-- Tabs -->
      <div class="tabs pt-3">
         
      </div>
      <!-- Content -->
      <div class="content">
        

<!-- Title -->
<div class="pp-card m-3" style="">
  <div class="card-header">
    <h2 class="card-title main-title text-center" style="">
      LAW
    </h2>
    <h3 class="card-subtitle mb-2 text-muted text-center">
      Organizers: 
      
      <a href="papers.html?filter=authors&search=Annemarie Friedrich&program=all"
        class="text-primary link-primary">Annemarie Friedrich</a>,
      
      <a href="papers.html?filter=authors&search=Jakob Prange&program=all"
        class="text-primary link-primary">Jakob Prange</a>,
      
      <a href="papers.html?filter=authors&search=Amir Zeldes&program=all"
        class="text-primary link-primary">Amir Zeldes</a>,
      
      <a href="papers.html?filter=authors&search=Ines Rehbein&program=all"
        class="text-primary link-primary">Ines Rehbein</a>
      
    </h3>
    <div class="text-muted text-center">
      Linguistic annotation of natural language corpora is the backbone of supervised methods of statistical natural language processing. The Linguistic Annotation Workshop (LAW) is the annual workshop of the ACL Special Interest Group on Annotation (SIGANN), and it provides a forum for the presentation and discussion of innovative research on all aspects of linguistic annotation, including the creation and evaluation of annotation schemes, methods for automatic and manual annotation, use and evaluation of annotation software and frameworks, representation of linguistic data and annotations, semi-supervised “human in the loop” methods of annotation, crowd-sourcing approaches, and more. As in the past, the LAW will provide a forum for annotation researchers to work towards standardization, best practices, and interoperability of annotation information and software.
    </div>
    <div class="text-center p-3">
      
      <a href="https://sigann.github.io/LAW-XVII-2023/" target="_blank" class="link-success">
        External Website
      </a>
      


    </div>

  </div>

  <!-- Schedule -->
  <!-- 
-->

  <div class="container" style="background-color:white; padding: 0px;">
    <div class="text-muted text-center">
      You can open
      the
      <a href="https://acl.rocket.chat/channel/workshop-LAW" target="_blank">
        #workshop-LAW
      </a>
      channel in separate windows.

    </div>

    <div class="row m-2">
      <div class="container" style="background-color:white; padding: 0px;">
        <!-- Chat -->
        <div id="gitter" class="slp">
          <iframe frameborder="0"
            src="https://acl.rocket.chat/channel/workshop-LAW?layout=embedded" height="700px"
            width="100%"></iframe>
        </div>
      </div>
    </div>
    <div class="row"><div class="col-12"><h3 class="text-center">Workshop Papers</h3></div></div>
    <div class="row" style='margin: 15px;'>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            A Dataset for Physical and Abstract Plausibility and Sources of Human Disagreement
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Annerose Eichel, Sabine Schulte Im Walde</h5>
            <p class="card-text">We present a novel dataset for physical and abstract plausibility of events in English. Based on naturally occurring sentences extracted from Wikipedia, we infiltrate degrees of abstractness, and automatically generate perturbed pseudo-implausible events. We annotate a filtered and balanced subset for plausibility using crowd-sourcing, and perform extensive cleansing to ensure annotation quality. In-depth quantitative analyses indicate that annotators favor plausibility over implausibility and disagree more on implausible events. Furthermore, our plausibility dataset is the first to capture abstractness in events to the same extent as concreteness, and we find that event abstractness has an impact on plausibility ratings: more concrete event participants trigger a perception of implausibility.</p>
            <a href="/paper_LAW_11.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Annotating and Disambiguating the Discourse Usage of the Enclitic dA in Turkish
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Ebru Ersöyleyen, Deniz Zeyrek, Fırat Öter</h5>
            <p class="card-text">The Turkish particle dA is a focus-associated enclitic, and it can act as a discourse connective conveying multiple senses, like additive, contrastive, causal etc. Like many other linguistic expressions, it is subject to usage ambiguity and creates a challenge in natural language automatization tasks. For the first time, we annotate the discourse and non-discourse connnective occurrences of dA in Turkish with the PDTB principles. Using a minimal set of linguistic features, we develop binary classifiers to distinguish its discourse connective usage from its other usages. We show that despite its ability to cliticize to any syntactic type, variable position in the sentence and having a wide argument span, its discourse/non-discourse connective usage can be annotated reliably and its discourse usage can be disambiguated by exploiting local cues.</p>
            <a href="/paper_LAW_12.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            An Active Learning Pipeline for NLU Error Detection in Conversational Agents
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Damian Pascual, Aritz Bercher, Akansha Bhardwaj, Mingbo Cui, Dominic Kohler, Liam Van Der Poel, Paolo Rosso</h5>
            <p class="card-text">High-quality labeled data is paramount to the performance of modern machine learning models. However, annotating data is a time-consuming and costly process that requires human experts to examine large collections of raw data. For conversational agents in production settings with access to large amounts of user-agent conversations, the challenge is to decide what data should be annotated first. We consider the Natural Language Understanding (NLU) component of a conversational agent deployed in a real-world setup with limited resources. We present an active learning pipeline for offline detection of classification errors that leverages two strong classifiers. Then, we perform topic modeling on the potentially mis-classified samples to ease data analysis and to reveal error patterns. In our experiments, we show on a real-world dataset that by using our method to prioritize data annotation we reach 100\% of the performance annotating only 36\% of the data. Finally, we present an analysis of some of the error patterns revealed and argue that our pipeline is a valuable tool to detect critical errors and reduce the workload of annotators.</p>
            <a href="/paper_LAW_13.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Multi-layered Annotation of Conversation-like Narratives in German
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Magdalena Repp, Petra B. Schumacher, Fahime Same</h5>
            <p class="card-text">This work presents two corpora based on excerpts from two novels with an informal narration style in German. We performed fine-grained multi-layer annotations of animate referents, assigning local and global prominence-lending features to the annotated referring expressions. In addition, our corpora include annotations of intra-sentential segments, which can serve as a more reliable unit of length measurement. Furthermore, we present two exemplary studies demonstrating how to use these corpora.</p>
            <a href="/paper_LAW_18.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Crowdsourcing on Sensitive Data with Privacy-Preserving Text Rewriting
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Nina Mouhammad, Johannes Daxenberger, Benjamin Schiller, Ivan Habernal</h5>
            <p class="card-text">Most tasks in NLP require labeled data. Data labeling is often done on crowdsourcing platforms due to scalability reasons. However, publishing data on public platforms can only be done if no privacy-relevant information is included. Textual data often contains sensitive information like person names or locations. In this work, we investigate how removing personally identifiable information (PII) as well as applying differential privacy (DP) rewriting can enable text with privacy-relevant information to be used for crowdsourcing. We find that DP-rewriting before crowdsourcing can preserve privacy while still leading to good label quality for certain tasks and data. PII-removal led to good label quality in all examined tasks, however, there are no privacy guarantees given.</p>
            <a href="/paper_LAW_20.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Extending an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned LLMs Suggestions
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Jana Straková, Eva Fučíková, Jan Hajič, Zdeňka Urešová</h5>
            <p class="card-text">In this project, we have investigated the use of advanced machine learning methods, specifically fine-tuned large language models, for pre-annotating data for a lexical extension task, namely adding descriptive words (verbs) to an existing (but incomplete, as of yet) ontology of event types. Several research questions have been focused on, from the investigation of a possible heuristics to provide at least hints to annotators which verbs to include and which are outside the current version of the ontology, to the possible use of the automatic scores to help the annotators to be more efficient in finding a threshold for identifying verbs that cannot be assigned to any existing class and therefore they are to be used as seeds for a new class. We have also carefully examined the correlation of the automatic scores with the human annotation. While the correlation turned out to be strong, its influence on the annotation proper is modest due to its near linearity, even though the mere fact of such pre-annotation leads to relatively short annotation times.</p>
            <a href="/paper_LAW_22.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Temporal and Second Language Influence on Intra-Annotator Agreement and Stability in Hate Speech Labelling
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Gavin Abercrombie, Dirk Hovy, Vinodkumar Prabhakaran</h5>
            <p class="card-text">Much work in natural language processing (NLP) relies on human annotation. The majority of this implicitly assumes that annotator&#39;s labels are temporally stable, although the reality is that human judgements are rarely consistent over time. As a subjective annotation task, hate speech labels depend on annotator&#39;s emotional and moral reactions to the language used to convey the message. Studies in Cognitive Science reveal a `foreign language effect&#39;, whereby people take differing moral positions and perceive offensive phrases to be weaker in their second languages. Does this affect annotations as well? We conduct an experiment to investigate the impacts of (1) time and (2) different language conditions (English and German) on measurements of intra-annotator agreement in a hate speech labelling task. While we do not observe the expected lower stability in the different language condition, we find that overall agreement is significantly lower than is implicitly assumed in annotation tasks, which has important implications for dataset reproducibility in NLP.</p>
            <a href="/paper_LAW_26.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            BenCoref: A Multi-Domain Dataset of Nominal Phrases and Pronominal Reference Annotations
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Shadman Rohan, Mojammel Hossain, Mohammad Rashid, Nabeel Mohammed</h5>
            <p class="card-text">Coreference Resolution is a well studied problem in NLP. While widely studied for English and other resource-rich languages, research on coreference resolution in Bengali largely remains unexplored due to the absence of relevant datasets. Bengali, being a low-resource language, exhibits greater morphological richness compared to English. In this article, we introduce a new dataset, BenCoref, comprising coreference annotations for Bengali texts gathered from four distinct domains. This relatively small dataset contains 5200 mention annotations forming 502 mention clusters within 48,569 tokens. We describe the process of creating this dataset and report performance of multiple models trained using BenCoref. We anticipate that our work sheds some light on the variations in coreference phenomena across multiple domains in Bengali and encourages the development of additional resources for Bengali. Furthermore, we found poor crosslingual performance at zero-shot  setting from English, highlighting the need for more language-specific resources for this task.</p>
            <a href="/paper_LAW_27.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Annotators-in-the-loop: Testing a Novel Annotation Procedure on Italian Case Law
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Emma Zanoli, Matilde Barbini, Davide Riva, Sergio Picascia, Emanuela Furiosi, Stefano D&#39;Ancona, Cristiano Chesi</h5>
            <p class="card-text">The availability of annotated legal corpora is crucial for a number of tasks, such as legal search, legal information retrieval, and predictive justice. Annotation is mostly assumed to be a straightforward task: as long as the annotation scheme is well defined and the guidelines are clear, annotators are expected to agree on the labels. This is not always the case, especially in legal annotation, which can be extremely difficult even for expert annotators. We propose a legal annotation procedure that takes into account annotator certainty and improves it through negotiation. We also collect annotator feedback and show that our approach contributes to a positive annotation environment. Our work invites reflection on often neglected ethical concerns regarding legal annotation.</p>
            <a href="/paper_LAW_28.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Annotating Decomposition in Time: Three Approaches for Again
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Martin Kopf, Remus Gergel</h5>
            <p class="card-text">This submission reports on a three-part series of original methods geared towards producing semantic annotations for the decompositional marker &#34;again&#34;. The three methods are (i) exhaustive expert annotation based on a comprehensive set of guidelines, (ii) extension of expert annotation by predicting presuppositions with a Multinomial Naïve Bayes classifier in the context of a meta-analysis to optimize feature selection and (iii) quality-controlled crowdsourcing with ensuing evaluation and KMeans clustering of annotation vectors.</p>
            <a href="/paper_LAW_33.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            How Good Is the Model in Model-in-the-loop Event Coreference Resolution Annotation?
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Shafiuddin Rehan Ahmed, Abhijnan Nath, Michael Regan, Adam Pollins, Nikhil Krishnaswamy, James H. Martin</h5>
            <p class="card-text">Annotating cross-document event coreference links is a time-consuming and cognitively demanding task that can compromise annotation quality and efficiency. To address this, we propose a model-in-the-loop annotation approach for event coreference resolution, where a machine learning model suggests likely corefering event pairs only. We evaluate the effectiveness of this approach by first simulating the annotation process and then, using a novel annotator-centric Recall-Annotation effort trade-off metric, we compare the results of various underlying models and datasets. We finally present a method for obtaining 97\% recall while substantially reducing the workload required by a fully manual annotation process.</p>
            <a href="/paper_LAW_34.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Pragmatic Annotation of Articles Related to Police Brutality
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Tess Feyen, Alda Mari, Paul Portner</h5>
            <p class="card-text">The annotation task we elaborated aims at describing the contextual factors that influence the appearance and interpretation of moral predicates, in newspaper articles on police brutality, in French and in English. The paper provides a brief review of the literature on moral predicates and their relation with context. The paper also describes the elaboration of the corpus and the ontology. Our hypothesis is that the use of moral adjectives and their appearance in context could change depending on the political orientation of the journal. We elaborated an annotation task to investigate the precise contexts discussed in articles on police brutality. The paper concludes by describing the study and the annotation task in details.</p>
            <a href="/paper_LAW_38.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            The RST Continuity Corpus
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Debopam Das, Markus Egg</h5>
            <p class="card-text">We present the RST Continuity Corpus (RST-CC), a corpus of discourse relations annotated for continuity dimensions. Continuity or discontinuity (maintaining or shifting deictic centres across discourse segments) is an important property of discourse relations, but the two are correlated in greatly varying ways. To analyse this correlation, the relations in the RST-CC are annotated using operationalised versions of Givón&#39;s (1993) continuity dimensions. We also report on the inter-annotator agreement, and discuss recurrent annotation issues. First results show substantial variation of continuity dimensions within and across relation types.</p>
            <a href="/paper_LAW_40.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            GENTLE: A Genre-Diverse Multilayer Challenge Set for English NLP and Linguistic Evaluation
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Tatsuya Aoyama, Shabnam Behzad, Luke Gessler, Lauren Levine, Jessica Lin, Yang Janet Liu, Siyao Peng, Yilun Zhu, Amir Zeldes</h5>
            <p class="card-text">We present GENTLE, a new mixed-genre English challenge corpus totaling 17K tokens and consisting of 8 unusual text types for out-of-domain evaluation: dictionary entries, esports commentaries, legal documents, medical notes, poetry, mathematical proofs, syllabuses, and threat letters. GENTLE is manually annotated for a variety of popular NLP tasks, including syntactic dependency parsing, entity recognition, coreference resolution, and discourse parsing. We evaluate state-of-the-art NLP systems on GENTLE and find severe degradation for at least some genres in their performance on all tasks, which indicates GENTLE&#39;s utility as an evaluation dataset for NLP systems.</p>
            <a href="/paper_LAW_41.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            A Study on Annotation Interfaces for Summary Comparison
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Sian Gooding, Lucas Werner, Victor Cărbune</h5>
            <p class="card-text">The task of summarisation is notoriously difficult to evaluate, with agreement even between expert raters unlikely to be perfect. One technique for summary evaluation relies on collecting comparison data by presenting annotators with generated summaries and tasking them with selecting the best one. This paradigm is currently being exploited in reinforcement learning using human feedback, whereby a reward function is trained using pairwise choice data. Comparisons are an easier way to elicit human feedback for summarisation, however, such decisions can be bottle necked by the usability of the annotator interface. In this paper, we present the results of a pilot study exploring how the user interface impacts annotator agreement when judging summary quality.</p>
            <a href="/paper_LAW_42.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            A Question Answering Benchmark Database for Hungarian
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Attila Novák, Borbála Novák, Tamás Zombori, Gergő Szabó, Zsolt Szántó, Richárd Farkas</h5>
            <p class="card-text">Within the research presented in this article, we created a new question answering benchmark database for Hungarian called MILQA. When creating the dataset, we basically followed the principles of the English SQuAD 2.0, however, like in some more recent English question answering datasets, we introduced a number of innovations beyond SQuAD: e.g., yes/no-questions, list-like answers consisting of several text spans, long answers, questions requiring calculation and other question types where you cannot simply copy the answer from the text. For all these non-extractive question types, the pragmatically adequate form of the answer was also added to make the training of generative models possible. We implemented and evaluated a set of baseline retrieval and answer span extraction models on the dataset. BM25 performed better than any vector-based solution for retrieval. Cross-lingual transfer from English significantly improved span extraction models.</p>
            <a href="/paper_LAW_44.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            No Strong Feelings One Way or Another: Re-operationalizing Neutrality in Natural Language Inference
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Animesh Nighojkar, Antonio Laverghetta Jr., John Licato</h5>
            <p class="card-text">Natural Language Inference (NLI) has been a cornerstone task in evaluating language models&#39; inferential reasoning capabilities. However, the standard three-way classification scheme used in NLI has well-known shortcomings in evaluating models&#39; ability to capture the nuances of natural human reasoning. In this paper, we argue that the operationalization of the neutral label in current NLI datasets has low validity, is interpreted inconsistently, and that at least one important sense of neutrality is often ignored. We uncover the detrimental impact of these shortcomings, which in some cases leads to annotation datasets that actually decrease performance on downstream tasks. We compare approaches of handling annotator disagreement and identify flaws in a recent NLI dataset that designs an annotator study based on a problematic operationalization. Our findings highlight the need for a more refined evaluation framework for NLI, and we hope to spark further discussion and action in the NLP community.</p>
            <a href="/paper_LAW_47.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            UMR-Writer 2.0: Incorporating a New Keyboard Interface and Workflow into UMR-Writer
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Sijia Ge, Jin Zhao, Kristin Wright-bettner, Skatje Myers, Nianwen Xue, Martha Palmer</h5>
            <p class="card-text">UMR-Writer is a web-based tool for annotating semantic graphs with the Uniform Meaning Representation (UMR) scheme. UMR is a graph-based semantic representation that can be applied cross-linguistically for deep semantic analysis of texts. In this work, we implemented a new keyboard interface in UMR-Writer 2.0, which is a powerful addition to the original mouse interface, supporting faster annotation for more experienced annotators. The new interface also addresses issues with the original mouse interface. Additionally, we demonstrate an efficient workflow for annotation project management in UMR-Writer 2.0, which has been applied to many projects.</p>
            <a href="/paper_LAW_48.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Unified Syntactic Annotation of English in the CGEL Framework
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Brett Reynolds, Aryaman Arora, Nathan Schneider</h5>
            <p class="card-text">We investigate whether the Cambridge Grammar of the English Language (2002) and its extensive descriptions work well as a corpus annotation scheme. We develop annotation guidelines and in the process outline some interesting linguistic uncertainties that we had to resolve. To test the applicability of CGEL to real-world corpora, we conduct an interannotator study on sentences from the English Web Treebank, showing that consistent annotation of even complex syntactic phenomena like gapping using the CGEL formalism is feasible. Why introduce yet another formalism for English syntax? We argue that CGEL is attractive due to its exhaustive analysis of English syntactic phenomena, its labeling of both constituents and functions, and its accessibility. We look towards expanding CGELBank and augmenting it with automatic conversions from existing treebanks in the future.</p>
            <a href="/paper_LAW_50.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Annotating Discursive Roles of Sentences in Patent Descriptions
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Lufei Liu, Xu Sun, François Veltz, Kim Gerdes</h5>
            <p class="card-text">Patent descriptions are a crucial component of patent applications, as they are key to understanding the invention and play a significant role in securing patent grants. While discursive analyses have been undertaken for scientific articles, they have not been as thoroughly explored for patent descriptions, despite the increasing importance of Intellectual Property and the constant rise of the number of patent applications. In this study, we propose an annotation scheme containing 16 classes that allows categorizing each sentence in patent descriptions according to their discursive roles. We publish an experimental human-annotated corpus of 16 patent descriptions and analyze challenges that may be encountered in such work. This work can be base for an automated annotation and thus contribute to enriching linguistic resources in the patent domain.</p>
            <a href="/paper_LAW_51.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            The Effect of Alignment Correction on Cross-Lingual Annotation Projection
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Shabnam Behzad, Seth Ebner, Marc Marone, Benjamin Van Durme, Mahsa Yarmohammadi</h5>
            <p class="card-text">Cross-lingual annotation projection is a practical method for improving performance on low resource structured prediction tasks. An important step in annotation projection is obtaining alignments between the source and target texts, which enables the mapping of annotations across the texts. By manually correcting automatically generated alignments, we examine the impact of alignment quality---automatic, manual, and mixed---on downstream performance for two information extraction tasks and quantify the trade-off between annotation effort and model performance.</p>
            <a href="/paper_LAW_52.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            When Do Annotator Demographics Matter? Measuring the Influence of Annotator Demographics with the POPQUORN Dataset
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Jiaxin Pei, David Jurgens</h5>
            <p class="card-text">Annotators are not fungible. Their demographics, life experiences, and backgrounds all contribute to how they label data. However, NLP has only recently considered how annotator identity might influence their decisions. Here, we present POPQUORN (the Potato-Prolific dataset for Question-Answering, Offensiveness, text Rewriting and politeness rating with demographic Nuance). POPQUORN contains 45,000 annotations from 1,484 annotators, drawn from a representative sample regarding sex, age, and race as the US population. Through a series of analyses, we show that annotators&#39; background plays a significant role in their judgments. Further, our work shows that backgrounds not previously considered in NLP (e.g., education), are meaningful and should be considered. Our study suggests that understanding the background of annotators and collecting labels from a demographically balanced pool of crowd workers is important to reduce the bias of datasets. The dataset, annotator background, and annotation interface are available at https://github.com/Jiaxin-Pei/potato-prolific-dataset.</p>
            <a href="/paper_LAW_54.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Enriching the NArabizi Treebank: A Multifaceted Approach to Supporting an Under-Resourced Language
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Arij Riabi, Menel Mahamdi, Djamé Seddah</h5>
            <p class="card-text">In this paper we address the scarcity of annotated data for NArabizi, a Romanized form of North African Arabic used mostly on  social media, which poses challenges for Natural Language Processing  (NLP). We introduce an enriched version of NArabizi Treebank (Seddah et al., 2020) with three main contributions: the addition of two novel annotation layers (named entity recognition and offensive language detection) and a re-annotation of the tokenization, morpho-syntactic and syntactic layers that ensure annotation consistency. Our experimental results, using different tokenization schemes, showcase the value of our contributions and highlight the impact of working with non-gold tokenization for NER and dependency parsing. To facilitate future research, we make these annotations publicly available. Our enhanced NArabizi Treebank paves the way for creating sophisticated language models and NLP tools for this under-represented language.</p>
            <a href="/paper_LAW_58.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Medieval Social Media: Manual and Automatic Annotation of Byzantine Greek Marginal Writing
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Colin Swaelens, Ilse De Vos, Els Lefever</h5>
            <p class="card-text">In this paper, we present the interim results of a transformer-based annotation pipeline for Ancient and Medieval Greek. As the texts in the Database of Byzantine Book Epigrams have not been normalised, they pose more challenges for manual and automatic annotation than Ancient Greek, normalised texts do. As a result, the existing annotation tools perform poorly. We compiled three data sets for the development of an automatic annotation tool and carried out an inter-annotator agreement study, with a promising agreement score. The experimental results show that our part-of-speech tagger yields accuracy scores that are almost 50 percentage points higher than the widely used rule-based system Morpheus. In addition, error analysis revealed problems related to phenomena also occurring in current social media language.</p>
            <a href="/paper_LAW_7.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            &#34;Orpheus Came to His End by Being Struck by a Thunderbolt&#34;: Annotating Events in Mythological Sequences
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Franziska Pannach</h5>
            <p class="card-text">The mythological domain has various ways of expressing events and background knowledge. Using data extracted according to the hylistic approach (Zgoll, 2019), we annotated a data set of 6315 sentences from various mythological contexts and geographical origins, like Ancient Greece and Rome or Mesopotamia, into four categories: single-point events (e.g. actions), durative-constant (background knowledge, continuous states), durative-initial, and durative-resultativ. This data is used to train a classifier, which is able to reliably distinguish event types.</p>
            <a href="/paper_LAW_8.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Difficulties in Handling Mathematical Expressions in Universal Dependencies
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Lauren Levine</h5>
            <p class="card-text">In this paper, we give a brief survey of the difficulties in handling the syntax of mathematical expressions in Universal Dependencies, focusing on examples from English language corpora. We first examine the prevalence and current handling of mathematical expressions in UD corpora. We then examine several strategies for how to approach the handling of syntactic dependencies for such expressions: as multi-word expressions, as a domain appropriate for code-switching, or as approximate to other types of natural language. Ultimately, we argue that  mathematical expressions should primarily be analyzed as natural language, and we offer recommendations for the treatment of basic mathematical expressions as analogous to English natural language.</p>
            <a href="/paper_LAW_9.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Verifying Annotation Agreement without Multiple Experts: A Case Study with Gujarati SNACS
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Maitrey Mehta, Vivek Srikumar</h5>
            <p class="card-text">Good datasets are a foundation of NLP research, and form the basis for training and evaluating models of language use. While creating datasets, the standard practice is to verify the annotation consistency using a committee of human annotators. This norm assumes that multiple annotators are available, which is not the case for highly specialized tasks or low-resource languages. In this paper, we ask: Can we evaluate the quality of a dataset constructed by a single human annotator? To address this question, we propose four weak verifiers to help estimate dataset quality, and outline when each may be employed. We instantiate these strategies for the task of semantic analysis of adpositions in Gujarati, a low-resource language, and show that our weak verifiers concur with a double-annotation study. As an added contribution, we also release the first dataset with semantic annotations in Gujarati along with several model baselines.</p>
            <a href="/paper_LAW_F1.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            HeGeL: A Novel Dataset for Geo-Location from Hebrew Text
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Tzuf Paz-Argaman, Tal Bauman, Itai Mondshine, Itzhak Omer, Sagi Dalyot, Reut Tsarfaty</h5>
            <p class="card-text">The task of textual geolocation retrieving the coordinates of a place based on a free-form language description calls for not only grounding but also natural language understanding and geospatial reasoning. Even though there are quite a few datasets in English used for geolocation, they are currently based on open-source data (Wikipedia and Twitter), where the location of the described place is mostly implicit, such that the location retrieval resolution is limited. Furthermore, there are no datasets available for addressing the problem of textual geolocation in morphologically rich and resource-poor languages, such as Hebrew. In this paper, we present the Hebrew Geo-Location (HeGeL) corpus, designed to collect literal place descriptions and analyze lingual geospatial reasoning. We crowdsourced 5,649 literal Hebrew place descriptions of various place types in three cities in Israel. Qualitative and empirical analysis show that the data exhibits abundant use of geospatial reasoning and requires a novel environmental representation.</p>
            <a href="/paper_LAW_F2.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            HaVQA: A Dataset for Visual Question Answering and Multimodal Research in Hausa Language
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Shantipriya Parida, Idris Abdulmumin, Shamsuddeen Muhammad, Aneesh Bose, Guneet Kohli, Ibrahim Ahmad, Ketan Kotwal, Sayan Deb Sarkar, Ondřej Bojar, Habeebah Kakudi</h5>
            <p class="card-text">This paper presents HaVQA, the first multi-modal dataset for visual question-answering (VQA) tasks in the Hausa language. The dataset was created by manually translating 6,022 English question-answer pairs, which are associated with 1,555 unique images from the Visual Genome dataset. As a result, the dataset provides 12,044 gold standard English-Hausa parallel sentences that were translated in a fashion that guarantees their semantic match with the corresponding visual information. We conducted several baseline experiments on the dataset, including visual question answering, visual question elicitation, text-only and multi-modal machine translation.</p>
            <a href="/paper_LAW_F3.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            An Investigation of Noise in Morphological Inflection
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Adam Wiemerslage, Changbing Yang, Garrett Nicolai, Miikka Silfverberg, Katharina Kann</h5>
            <p class="card-text">With a growing focus on morphological inflection systems for languages where high-quality data is scarce, training data noise is a serious but so far largely ignored concern. We aim at closing this gap by investigating the types of noise encountered within a pipeline for truly unsupervised morphological paradigm completion and its impact on morphological inflection systems: First, we propose an error taxonomy and annotation pipeline for inflection training data. Then, we compare the effect of different types of noise on multiple state-of-the-art inflection models. Finally, we propose a novel character-level masked language modeling (CMLM) pretraining objective and explore its impact on the models&#39; resistance to noise.  Our experiments show that various architectures are impacted differently by separate types of noise, but encoder-decoders tend to be more robust to noise than models trained with a copy bias. CMLM pretraining helps transformers, but has lower impact on LSTMs.</p>
            <a href="/paper_LAW_F4.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Common Law Annotations: Investigating the Stability of Dialog System Output Annotations
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Seunggun Lee, Alexandra DeLucia, Nikita Nangia, Praneeth Ganedi, Ryan Guan, Rubing Li, Britney Ngaw, Aditya Singhal, Shalaka Vaidya, Zijun Yuan, Lining Zhang, João Sedoc</h5>
            <p class="card-text">Metrics for Inter-Annotator Agreement (IAA), like Cohen&#39;s Kappa, are crucial for validating annotated datasets. Although high agreement is often used to show the reliability of annotation procedures, it is insufficient to ensure validity or reproducibility. While researchers are encouraged to increase annotator agreement, this can lead to specific and tailored annotation guidelines. We hypothesize that this may result in diverging annotations from different groups. To study this, we first propose the Lee et al. Protocol (LEAP), a standardized and codified annotation protocol. LEAP strictly enforces transparency in the annotation process, which ensures reproducibility of annotation guidelines. Using LEAP to annotate a dialog dataset, we empirically show that while research groups may create reliable guidelines by raising agreement, this can cause divergent annotations across different research groups, thus questioning the validity of the annotations. Therefore, we caution NLP researchers against using reliability as a proxy for reproducibility and validity.</p>
            <a href="/paper_LAW_F5.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Multi-lingual and Multi-cultural Figurative Language Understanding
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Anubha Kabra, Emmy Liu, Simran Khanuja, Alham Fikri Aji, Genta Winata, Samuel Cahyawijaya, Anuoluwapo Aremu, Perez Ogayo, Graham Neubig</h5>
            <p class="card-text">Figurative language permeates human communication, but at the same time is relatively understudied in NLP. Datasets have been created in English to accelerate progress towards measuring and improving figurative language processing in language models (LMs). However, the use of figurative language is an expression of our cultural and societal experiences, making it difficult for these phrases to be universally applicable. In this work, we create a figurative language inference dataset, MABL, for seven diverse languages associated with a variety of cultures: Hindi, Indonesian, Javanese, Kannada, Sundanese, Swahili and Yoruba. Our dataset reveals that each language relies on cultural and regional concepts for figurative expressions, with the highest overlap between languages originating from the same region. We assess multilingual LMs&#39; abilities to interpret figurative language in zero-shot and few-shot settings. All languages exhibit a significant deficiency compared to English, with variations in performance reflecting the availability of pre-training and fine-tuning data, emphasizing the need for LMs to be exposed to a broader range of linguistic and cultural variation during training.</p>
            <a href="/paper_LAW_F6.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            A Call for Standardization and Validation of Text Style Transfer Evaluation
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Phil Ostheimer, Mayank Kumar Nagda, Marius Kloft, Sophie Fellenz</h5>
            <p class="card-text">Text Style Transfer (TST) evaluation is, in practice, inconsistent. Therefore, we conduct a meta-analysis on human and automated TST evaluation and experimentation that thoroughly examines existing literature in the field. The meta-analysis reveals a substantial standardization gap in human and automated evaluation. In addition, we also find a validation gap: only few automated metrics have been validated using human experiments. To this end, we thoroughly scrutinize both the standardization and validation gap and reveal the resulting pitfalls. This work also paves the way to close the standardization and validation gap in TST evaluation by calling out requirements to be met by future research.</p>
            <a href="/paper_LAW_F7.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            GUMSum: Multi-Genre Data and Evaluation for English Abstractive Summarization
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Yang Janet Liu, Amir Zeldes</h5>
            <p class="card-text">Automatic summarization with pre-trained language models has led to impressively fluent results, but is prone to `hallucinations&#39;, low performance on non-news genres, and outputs which are not exactly summaries. Targeting ACL 2023&#39;s &#39;Reality Check&#39; theme, we present GUMSum, a small but carefully crafted dataset of English summaries in 12 written and spoken genres for evaluation of abstractive summarization. Summaries are highly constrained, focusing on substitutive potential, factuality, and faithfulness. We present guidelines and evaluate human agreement as well as subjective judgments on recent system outputs, comparing general-domain untuned approaches, a fine-tuned one, and a prompt-based approach, to human performance. Results show that while GPT3 achieves impressive scores, it still underperforms humans, with varying quality across genres. Human judgments reveal different types of errors in supervised, prompted, and human-generated summaries, shedding light on the challenges of producing a good summary.</p>
            <a href="/paper_LAW_F8.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            The Coreference under Transformation Labeling Dataset: Entity Tracking in Procedural Texts Using Event Models
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Kyeongmin Rim, Jingxuan Tu, Bingyang Ye, Marc Verhagen, Eben Holderness, James Pustejovsky</h5>
            <p class="card-text">We demonstrate that coreference resolution in procedural texts is significantly improved when performing transformation-based entity linking prior to coreference relation identification. When events in the text introduce changes to the state of participating entities, it is often impossible to accurately link entities in anaphoric and coreference relations without an understanding of the transformations those entities undergo. We show how adding event semantics helps to better model entity coreference. We argue that all transformation predicates, not just creation verbs, introduce a new entity into the discourse, as a kind of generalized Result Role, which is typically not textually mentioned. This allows us to model procedural texts as process graphs and to compute the coreference type for any two entities in the recipe. We present our annotation methodology and the corpus generated as well as describe experiments on coreference resolution of entity mentions under a process-oriented model of events.</p>
            <a href="/paper_LAW_F9.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
    </div>


    <script src="static/js/time-extend.js"></script>
    <script>
      $(document).ready(() => {
        add_local_tz('.session_times');
      })
    </script>

    
      </div>
    </div>
    
    

    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=None"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());
      gtag("config", "None");
    </script>

    <!-- Footer -->
    <footer class="footer bg-light p-4">
      <div class="container">
        <p class="float-left">
          <img src="static/images/acl2023/acl-logo-2023.png" height="45px"
            width="auto" align="center">
          <span class="lead">ACL 2023</span>
        </p>
        <p class="float-right"><a href="#" class="text-dark">Back to Top</a></p>
        <p class="text-center">© 2023 Association for Computational Linguistics</p>
      </div>
    </footer>

    <!-- Code for hash tags -->
    <script type="text/javascript">
      $(document).ready(function () {
        if (location.hash !== "") {
          $('a[href="' + location.hash + '"]').tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          var hash = $(e.target).attr("href");
          if (hash.substr(0, 1) == "#") {
            var position = $(window).scrollTop();
            location.replace("#" + hash.substr(1));
            $(window).scrollTop(position);
          }
        });
      });
    </script>
    <script src="static/js/lazy_load.js"></script>
    
    <div class="modal left fade" id="chatsModal" tabindex="" role="dialog" aria-labelledby="exampleModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-dialog-scrollable" role="document" style="max-height: 100% !important;">
        <div class="modal-content" style="max-height: 100% !important;">
            <div class="modal-header">
                <h4 class="modal-title" id="exampleModalLabel">Active Chats</h4>
                <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
            </div>
            <div class="modal-body">
                <div style="margin-bottom: 1em;">
    <div class="stats-last-update text-muted" id="highly-active-chats-last-update"></div>
    <a id="highly-active-chats-btn-refresh" href="#" class="text-primary" style="display: none;">Refresh now</a>
</div>

<div id="highly-active-chats-list">
</div>

<div class="text-center" id="highly-active-chats-progress-bar" style="margin-bottom: 80em;">
    <div class="spinner-border text-primary" style="margin-top: 3em; width: 3rem; height: 3rem;" role="status">
      <span class="sr-only">Loading...</span>
    </div>
</div>

<br/>
<p class="text-muted">
    <strong>How it works: </strong>
    We calculate the number of new messages for every channel in the last N seconds. Then, we sort them descendingly.
    Channels with no new messages will be randomly shuffled. Please note that the number of messages might not be accurate.
</p>

<script src="static/js/highly-active-chats.js"></script>
<script>
    let channel_stats_server = "https://emnlp2020-channels-stats.azure-api.net"
    $(document).ready( function () {
        $('[data-toggle="tooltip"]').tooltip();
        //load_stats();
    });
</script>

            </div>

            <div class="modal-footer">
                <button type="button" class="btn btn-secondary btn-sm" data-dismiss="modal">Close</button>
            </div>
        </div>
    </div>
</div>
</body>

</html>