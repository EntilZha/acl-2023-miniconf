


<!DOCTYPE html>
<html lang="en">

<head>
  
  <!-- Required meta tags -->
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />


  <!-- External Javascript libs  -->
  <script src="https://cdn.jsdelivr.net/npm/d3@5/dist/d3.min.js"></script>

  <script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js"
    integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script>

  <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"
    integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>

  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
    integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
    crossorigin="anonymous"></script>


  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js"
    integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script>

  <script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js"
    integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script>

  <script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js"
    integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script>

  <!-- https://developer.snapappointments.com/bootstrap-select/ -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-select@1.13.14/dist/css/bootstrap-select.min.css">
  <script src="https://cdn.jsdelivr.net/npm/bootstrap-select@1.13.14/dist/js/bootstrap-select.min.js"></script>

  <!-- Library libs -->
  <script src="static/js/typeahead.bundle.js"></script>

  <script src="https://craig.global.ssl.fastly.net/js/mousetrap/mousetrap.min.js?a4098"></script>

  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.0/css/all.css"
    integrity="sha384-lZN37f5QGtY3VHgisS14W3ExzMWZxybE1SJSEsQp9S+oqd12jhcu+A56Ebc1zFSJ" crossorigin="anonymous">

  <!-- External CSS -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css"
    integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous">

  <!-- External Fonts (no google for china) -->
  <link href="static/css/Lato.css" rel="stylesheet" />
  <link href="static/css/Exo.css" rel="stylesheet" />
  <link href="static/css/Cuprum.css" rel="stylesheet" />

  <link rel="stylesheet" href="static/css/main.css" />
  <link rel="stylesheet" href="static/css/chats-modal.css" />
  <link rel="stylesheet" href="static/css/lazy_load.css" />
  <link rel="stylesheet" href="static/css/typeahead.css" />
  <script src="https://cdn.jsdelivr.net/npm/pdfjs-dist@2.3.200/build/pdf.min.js"></script>
  <script src="static/js/pdf_render.js"></script>

  <title>ACL2023: WASSA</title>
  

  <!-- Favicon -->
  <link rel="apple-touch-icon" sizes="180x180" href="static/favicon/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="static/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="static/favicon/favicon-16x16.png">
  <link rel="manifest" href="static/favicon/site.webmanifest">
  <link rel="mask-icon" href="static/favicon/safari-pinned-tab.svg" color="#5bbad5">
  <link rel="shortcut icon" href="static/favicon/favicon.ico">
  <meta name="msapplication-TileColor" content="#2d89ef">
  <meta name="msapplication-config" content="static/favicon/browserconfig.xml">
  <meta name="theme-color" content="#ffffff">
</head>

<body>
  <!-- NAV -->
  
  <!-- ('https://2023.aclweb.org/faq/', 'FAQ'), -->
  <!-- ('https://2023.aclweb.org/committees/organization/', 'Organizers'), -->
  <!-- ('https://2023.aclweb.org/sponsors/', 'Sponsors') -->

  <!-- Add back ('livestream.html', 'Livestream'),
    ('about.html', 'Help'),
    ('plenary_sessions.html', 'Plenary'),
    ('livestream.html', 'Livestream'),
    (config.gather_town , 'Gather'),
    for a new conference
    -->

  <nav class="navbar sticky-top navbar-expand-lg navbar-light  bg-emnlp mr-auto customnav" id="main-nav">
    <div class="container">
      <a class="navbar-brand" href="index.html">
        <img class="logo" src="static/images/acl2023/acl-logo-2023.png" height="45px"
          width="auto" alt="ACL 2023" />
      </a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav"
        aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
        <ul class="navbar-nav ml-auto">
          
          <li class="nav-item ">
            
            <a class="nav-link" href="index.html">Home</a>
            
          </li>
          
          <li class="nav-item ">
            
            <a class="nav-link" href="schedule.html">Schedule</a>
            
          </li>
          
          <li class="nav-item ">
            
            <a class="nav-link" href="sessions.html">Sessions</a>
            
          </li>
          
          <li class="nav-item ">
            
            <a class="nav-link" href="papers.html">Papers</a>
            
          </li>
          
          <li class="nav-item ">
            
            <a class="nav-link" href="tutorials.html">Tutorials</a>
            
          </li>
          
          <li class="nav-item ">
            
            <a class="nav-link" href="workshops.html">Workshops</a>
            
          </li>
          
          <li class="nav-item ">
            
            <a class="nav-link" href="map.html">Map</a>
            
          </li>
          
          <li class="nav-item ">
            
            <a class="nav-link" href="https://acl.rocket.chat" target="_blank"><u>Chat</u></a>
            
          </li>
          
          <li class="nav-item ">
            
            <a class="nav-link" href="https://app.gather.town/app/5OscLswEEuYf2Psb/ACL2023" target="_blank"><u>GatherTown</u></a>
            
          </li>
          
          <li class="nav-item ">
            
            <a class="nav-link" href="https://2023.aclweb.org/" target="_blank"><u>Main Site</u></a>
            
          </li>
          
          <li class="nav-item ">
            
            <a class="nav-link" href="https://2023.aclweb.org/downloads/acl2023-handbook.pdf" target="_blank"><u>Handbook</u></a>
            
          </li>
          
        </ul>
      </div>
    </div>
  </nav>
  

  
  <!-- User Overrides -->
   

      
      <div class="container">
        
    <!-- Heading -->
    <div class="heading">
       
    </div>
    <div class="tabs pt-3">
      <!-- Tabs -->
      <div class="tabs pt-3">
         
      </div>
      <!-- Content -->
      <div class="content">
        

<!-- Title -->
<div class="pp-card m-3" style="">
  <div class="card-header">
    <h2 class="card-title main-title text-center" style="">
      WASSA
    </h2>
    <h3 class="card-subtitle mb-2 text-muted text-center">
      Organizers: 
      
      <a href="papers.html?filter=authors&search=Jeremy Barnes&program=all"
        class="text-primary link-primary">Jeremy Barnes</a>,
      
      <a href="papers.html?filter=authors&search=Orphée De Clercq&program=all"
        class="text-primary link-primary">Orphée De Clercq</a>,
      
      <a href="papers.html?filter=authors&search=Roman Klinger&program=all"
        class="text-primary link-primary">Roman Klinger</a>,
      
      <a href="papers.html?filter=authors&search=Valentin Barriere&program=all"
        class="text-primary link-primary">Valentin Barriere</a>,
      
      <a href="papers.html?filter=authors&search=Salvatore Giorgi&program=all"
        class="text-primary link-primary">Salvatore Giorgi</a>,
      
      <a href="papers.html?filter=authors&search=Joaõ Sedoc&program=all"
        class="text-primary link-primary">Joaõ Sedoc</a>,
      
      <a href="papers.html?filter=authors&search=Shabnam Tafreshi&program=all"
        class="text-primary link-primary">Shabnam Tafreshi</a>,
      
      <a href="papers.html?filter=authors&search=Iqra Ameer&program=all"
        class="text-primary link-primary">Iqra Ameer</a>,
      
      <a href="papers.html?filter=authors&search=Necva Bölücü&program=all"
        class="text-primary link-primary">Necva Bölücü</a>,
      
      <a href="papers.html?filter=authors&search=Hua Xu&program=all"
        class="text-primary link-primary">Hua Xu</a>,
      
      <a href="papers.html?filter=authors&search=Ali Al Bataineh&program=all"
        class="text-primary link-primary">Ali Al Bataineh</a>
      
    </h3>
    <div class="text-muted text-center">
      Subjectivity and Sentiment Analysis has become a highly developed research area, ranging from binary classification of reviews to the detection of complex emotion structures between entities found in text. This field has expanded both on a practical level, finding numerous successful applications in business, as well as on a theoretical level, allowing researchers to explore more complex research questions related to affective computing. Its continuing importance is also shown by the interest it generates in other disciplines such as Economics, Sociology, Psychology, Marketing, Crisis Management \& Digital Humanities. \\newline The aim of WASSA 2023 is to bring together researchers working on Subjectivity, Sentiment Analysis, Emotion Detection and Classification and their applications to other NLP or real-world tasks (e.g. public health messaging, fake news, media impact analysis, social media mining, computational literary studies) and researchers working on interdisciplinary aspects of affect computation from text.
    </div>
    <div class="text-center p-3">
      
      <a href="https://wassa-workshop.github.io/" target="_blank" class="link-success">
        External Website
      </a>
      


    </div>

  </div>

  <!-- Schedule -->
  <!-- 
-->

  <div class="container" style="background-color:white; padding: 0px;">
    <div class="text-muted text-center">
      You can open
      the
      <a href="https://acl.rocket.chat/channel/workshop-WASSA" target="_blank">
        #workshop-WASSA
      </a>
      channel in separate windows.

    </div>

    <div class="row m-2">
      <div class="container" style="background-color:white; padding: 0px;">
        <!-- Chat -->
        <div id="gitter" class="slp">
          <iframe frameborder="0"
            src="https://acl.rocket.chat/channel/workshop-WASSA?layout=embedded" height="700px"
            width="100%"></iframe>
        </div>
      </div>
    </div>
    <div class="row"><div class="col-12"><h3 class="text-center">Workshop Papers</h3></div></div>
    <div class="row" style='margin: 15px;'>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            PESTO: A Post-User Fusion Network for Rumour Detection on Social Media
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Erxue Min, Sophia Ananiadou</h5>
            <p class="card-text">Rumour detection on social media is an important topic due to the challenges of misinformation propagation and slow verification of misleading information. Most previous work focus on the response posts on social media, ignoring the useful characteristics of involved users and their relations. In this paper, we propose a novel framework, Post-User Fusion Network (PESTO), which models the patterns of rumours from both post diffusion and user social networks. Specifically, we propose a novel Chronologically-masked Transformer architecture to model both temporal sequence and diffusion structure of rumours, and apply a Relational Graph Convolutional Network to model the social relations of involved users, with a fusion network based on self-attention mechanism to incorporate the two aspects. Additionally, two data augmentation techniques are leveraged to improve the robustness and accuracy of our models. Empirical results on four datasets of English tweets show the superiority of the proposed method.</p>
            <a href="/paper_WASSA_1.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            UNIDECOR: A Unified Deception Corpus for Cross-Corpus Deception Detection
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Aswathy Velutharambath, Roman Klinger</h5>
            <p class="card-text">Verbal deception has been studied in psychology, forensics, and computational linguistics for a variety of reasons, like understanding behaviour patterns, identifying false testimonies, and detecting deception in online communication. Varying motivations across research fields lead to differences in the domain choices to study and in the conceptualization of deception, making it hard to compare models and build robust deception detection systems for a given language. With this paper, we improve this situation by surveying available English deception datasets which include domains like social media reviews, court testimonials, opinion statements on specific topics, and deceptive dialogues from online strategy games. We consolidate these datasets into a single unified corpus. Based on this resource, we conduct a correlation analysis of linguistic cues of deception across datasets to understand the differences and perform cross-corpus modeling experiments which show that a cross-domain generalization is challenging to achieve. The unified deception corpus (UNIDECOR) can be obtained from   https://www.ims.uni-stuttgart.de/data/unidecor.</p>
            <a href="/paper_WASSA_10.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Findings of WASSA 2023 Shared Task on Empathy, Emotion and Personality Detection in Conversation and Reactions to News Articles
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Valentin Barriere, João Sedoc, Shabnam Tafreshi, Salvatore Giorgi</h5>
            <p class="card-text">This paper presents the results of the WASSA 2023 shared task on predicting empathy, emotion, and personality in conversations and reactions to news articles. Participating teams were given access to a new dataset from Omitaomu et al. (2022) comprising empathic and emotional reactions to news articles. The dataset included formal and informal text, self-report data, and third-party annotations. Specifically, the dataset contained news articles (where harm is done to a person, group, or other) and crowd-sourced essays written in reaction to the article. After reacting via essays, crowd workers engaged in conversations about the news articles. Finally, the crowd workers self-reported their empathic concern and distress, personality (using the Big Five), and multi-dimensional empathy (via the Interpersonal Reactivity Index). A third-party annotated both the conversational turns (for empathy, emotion polarity, and emotion intensity) and essays (for multi-label emotions). Thus, the dataset contained outcomes (self-reported or third-party annotated) at the turn level (within conversations) and the essay level. Participation was encouraged in five tracks: (i) predicting turn-level empathy, emotion polarity, and emotion intensity in conversations, (ii) predicting state empathy and distress scores, (iii) predicting emotion categories, (iv) predicting personality, and (v) predicting multi-dimensional trait empathy. In total, 21 teams participated in the shared task. We summarize the methods and resources used by the participating teams.</p>
            <a href="/paper_WASSA_101.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            YNU-HPCC at WASSA-2023 Shared Task 1: Large-scale Language Model with LoRA Fine-Tuning for Empathy Detection and Emotion Classification
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Yukun Wang, Jin Wang, Xuejie Zhang</h5>
            <p class="card-text">This paper describes the system for the YNU-HPCC team in WASSA-2023 Shared Task 1: Empathy Detection and Emotion Classification. This task needs to predict the empathy, emotion, and personality of the empathic reactions. This system is mainly based on the Decoding-enhanced BERT with disentangled attention (DeBERTa) model with parameter-efficient fine-tuning (PEFT) and the Robustly Optimized BERT Pretraining Approach (RoBERTa). Low-Rank Adaptation (LoRA) fine-tuning in PEFT is used to reduce the training parameters of large language models. Moreover, back translation is introduced to augment the training dataset. This system achieved relatively good results on the competition’s official leaderboard. The code of this system is available here.</p>
            <a href="/paper_WASSA_102.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            AdityaPatkar at WASSA 2023 Empathy, Emotion, and Personality Shared Task: RoBERTa-Based Emotion Classification of Essays, Improving Performance on Imbalanced Data
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Aditya Patkar, Suraj Chandrashekhar, Ram Mohan Rao Kadiyala</h5>
            <p class="card-text">This paper presents a study on using the RoBERTa language model for emotion classification of essays as part of the &#39;Shared Task on Empathy Detection, Emotion Classification and Personality Detection in Interactions&#39; organized as part of &#39;WASSA 2023&#39; at &#39;ACL 2023&#39;. Emotion classification is a challenging task in natural language processing, and imbalanced datasets further exacerbate this challenge. In this study, we explore the use of various data balancing techniques in combination with RoBERTa to improve the classification performance. We evaluate the performance of our approach (denoted by adityapatkar on Codalab) on a benchmark multi-label dataset of essays annotated with eight emotion categories, provided by the Shared Task organizers. Our results show that the proposed approach achieves the best macro F1 score in the competition&#39;s training and evaluation phase. Our study provides insights into the potential of RoBERTa for handling imbalanced data in emotion classification. The results can have implications for the natural language processing tasks related to emotion classification.</p>
            <a href="/paper_WASSA_103.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Curtin OCAI at WASSA 2023 Empathy, Emotion and Personality Shared Task: Demographic-Aware Prediction Using Multiple Transformers
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Md Rakibul Hasan, Md Zakir Hossain, Tom Gedeon, Susannah Soon, Shafin Rahman</h5>
            <p class="card-text">The WASSA 2023 shared task on predicting empathy, emotion and other personality traits consists of essays, conversations and articles in textual form and participants’ demographic information in numerical form. To address the tasks, our contributions include (1) converting numerical information into meaningful text information using appropriate templates, (2) summarising lengthy articles, and (3) augmenting training data by paraphrasing. To achieve these contributions, we leveraged two separate T5-based pre-trained transformers. We then fine-tuned pre-trained BERT, DistilBERT and ALBERT for predicting empathy and personality traits. We used the Optuna hyperparameter optimisation framework to fine-tune learning rates, batch sizes and weight initialisation. Our proposed system achieved its highest performance – a Pearson correlation coefficient of 0.750 – on the  onversation-level empathy prediction task1 . The system implementation is publicly available at https: //github.com/hasan-rakibul/WASSA23-empathy-emotion.</p>
            <a href="/paper_WASSA_104.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Team_Hawk at WASSA 2023 Empathy, Emotion, and Personality Shared Task: Multi-tasking Multi-encoder based transformers for Empathy and Emotion Prediction in Conversations
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Addepalli Sai Srinivas, Nabarun Barua, Santanu Pal</h5>
            <p class="card-text">In this paper, we present Team Hawk&#39;s participation in Track 1 of the WASSA 2023 shared task. The objective of the task is to understand the empathy that emerges between individuals during their conversations. In our study, we developed a multi-tasking framework that is capable of automatically assessing empathy, intensity of emotion, and polarity of emotion within participants&#39; conversations. Our proposed core model extends the transformer architecture, utilizing two separate RoBERTa-based encoders to encode both the articles and conversations. Subsequently, a sequence of self-attention, position-wise feed-forward, and dense layers are employed to predict the regression scores for the three sub-tasks: empathy, intensity of emotion, and polarity of emotion. Our best model achieved average Pearson&#39;s correlation of 0.7710 (Empathy: 0.7843, Emotion Polarity: 0.7917, Emotion Intensity: 0.7381) on the released  development set and 0.7250 (Empathy: 0.8090, Emotion Polarity: 0.7010, Emotion Intensity: 0.6650) on the released test set. These results earned us the 3rd position in the test set evaluation phase of Track 1.</p>
            <a href="/paper_WASSA_105.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            NCUEE-NLP at WASSA 2023 Shared Task 1: Empathy and Emotion Prediction Using Sentiment-Enhanced RoBERTa Transformers
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Tzu-Mi Lin, Jung-Ying Chang, Lung-Hao Lee</h5>
            <p class="card-text">This paper describes our proposed system design for the WASSA 2023 shared task 1. We propose a unified architecture of ensemble neural networks to integrate the original RoBERTa transformer with two sentiment-enhanced RoBERTa-Twitter and EmoBERTa models. For Track 1 at the speech-turn level, our best submission achieved an average Pearson correlation score of 0.7236, ranking fourth for empathy, emotion polarity and emotion intensity prediction. For Track 2 at the essay-level, our best submission obtained an average Pearson correlation score of 0.4178 for predicting empathy and distress scores, ranked first among all nine submissions.</p>
            <a href="/paper_WASSA_106.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Domain Transfer for Empathy, Distress, and Personality Prediction
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Fabio Gruschka, Allison Lahnala, Charles Welch, Lucie Flek</h5>
            <p class="card-text">This research contributes to the task of predicting empathy and personality traits within dialogue, an important aspect of natural language processing, as part of our experimental work for the WASSA 2023 Empathy and Emotion Shared Task. For predicting empathy, emotion polarity, and emotion intensity on turns within a dialogue, we employ adapters trained on social media interactions labeled with empathy ratings in a stacked composition with the target task adapters. Furthermore, we embed demographic information to predict Interpersonal Reactivity Index (IRI) subscales and Big Five Personality Traits utilizing BERT-based models. The results from our study provide valuable insights, contributing to advancements in understanding human behavior and interaction through text. Our team ranked 2nd on the personality and empathy prediction tasks, 4th on the interpersonal reactivity index, and 6th on the conversational task.</p>
            <a href="/paper_WASSA_107.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Converge at WASSA 2023 Empathy, Emotion and Personality Shared Task: A Transformer-based Approach for Multi-Label Emotion Classification
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Aditya Paranjape, Gaurav Kolhatkar, Yash Patwardhan, Omkar Gokhale, Shweta Dharmadhikari</h5>
            <p class="card-text">In this paper, we highlight our approach for the &#34;WASSA 2023 Shared-Task 1: Empathy Detection and Emotion Classification&#34;. By accurately identifying emotions from textual sources of data, deep learning models can be trained to understand and interpret human emotions more effectively. The classification of emotions facilitates the creation of more emotionally intelligent systems that can better understand and respond to human emotions. We compared multiple transformer-based models for multi-label classification. Ensembling and oversampling were used to improve the performance of the system. A threshold-based voting mechanism performed on three models (Longformer, BERT, BigBird) yields the highest overall macro F1-score of 0.6605.</p>
            <a href="/paper_WASSA_108.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            PICT-CLRL at WASSA 2023 Empathy, Emotion and Personality Shared Task: Empathy and Distress Detection using Ensembles of Transformer Models
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Tanmay Chavan, Kshitij Deshpande, Sheetal Sonawane</h5>
            <p class="card-text">This paper presents our approach for the WASSA 2023 Empathy, Emotion and Personality Shared Task. Empathy and distress are human feelings that are implicitly expressed in natural discourses. Empathy and distress detection are crucial challenges in Natural Language Processing that can aid our understanding of conversations. The provided dataset consists of several long-text examples in the English language, with each example associated with a numeric score for empathy and distress. We experiment with several BERT-based models as a part of our approach. We also try various ensemble methods. Our final submission has a Pearson&#39;s r score of 0.346, placing us third in the empathy and distress detection subtask.</p>
            <a href="/paper_WASSA_109.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Discourse Mode Categorization of Bengali Social Media Health Text
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Salim Sazzed</h5>
            <p class="card-text">The scarcity of annotated data is a major impediment to natural language processing (NLP) research in Bengali, a language that is considered low-resource. In particular, the health and medical domains suffer from a severe paucity of annotated data. Thus, this study aims to introduce BanglaSocialHealth, an annotated social media health corpus that provides sentence-level annotations of four distinct types of expression modes, namely narrative (NAR), informative (INF), suggestive (SUG), and inquiring (INQ) modes in Bengali. We provide details regarding the annotation procedures and report various statistics, such as the median and mean length of words in different sentence modes. Additionally, we apply classical machine learning (CML) classifiers and transformer-based language models to classify sentence modes. We find that most of the statistical properties are similar in different types of sentence modes. To determine the sentence mode, the transformer-based M-BERT model provides slightly better efficacy than the CML classifiers. Our developed corpus and analysis represent a much-needed contribution to Bengali NLP research in medical and health domains and have the potential to facilitate a range of downstream tasks, including question-answering, misinformation detection, and information retrieval.</p>
            <a href="/paper_WASSA_11.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Team Bias Busters at WASSA 2023 Empathy, Emotion and Personality Shared Task: Emotion Detection with Generative Pretrained Transformers
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Andrew Nedilko, Yi Chu</h5>
            <p class="card-text">This paper describes the approach that we used to take part in the multi-label multi-class emotion classification as Track 3 of the WASSA 2023 Empathy, Emotion and Personality Shared Task at ACL 2023. The overall goal of this track is to build models that can predict 8 classes (7 emotions + neutral) based on short English essays written in response to news article that talked about events perceived as harmful to people. We used OpenAI generative pretrained transformers with full-scale APIs for the emotion prediction task by fine-tuning a GPT-3 model and doing prompt engineering for zero-shot / few-shot learning with ChatGPT and GPT-4 models based on multiple experiments on the dev set. The most efficient method was fine-tuning a GPT-3 model which allowed us to beat our baseline character-based XGBoost Classifier and rank 2nd among all other participants by achieving a macro F1 score of 0.65 and a micro F1 score of 0.7 on the final blind test set.</p>
            <a href="/paper_WASSA_110.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            HIT-SCIR at WASSA 2023: Empathy and Emotion Analysis at the Utterance-Level and the Essay-Level
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Xin Lu, Zhuojun Li, Yanpeng Tong, Yanyan Zhao, Bing Qin</h5>
            <p class="card-text">This paper introduces the participation of team HIT-SCIR to the WASSA 2023 Shared Task on Empathy Detection and Emotion Classification and Personality Detection in Interactions. We focus on three tracks: Track 1 (Empathy and Emotion Prediction in Conversations, CONV), Track 2 (Empathy Prediction, EMP) and Track 3 (Emotion Classification, EMO), and designed three different models to address them separately. For Track 1, we designed a direct fine-tuning DeBERTa model for three regression tasks at the utterance-level. For Track 2, we designed a multi-task learning RoBERTa model for two regression tasks at the essay-level. For Track 3, we designed a RoBERTa model with data augmentation for the classification task at the essay-level. Finally, our team ranked 1st in the Track 1 (CONV), 5th in the Track 2 (EMP) and 3rd in the Track 3 (EMO) in the evaluation phase.</p>
            <a href="/paper_WASSA_111.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            VISU at WASSA 2023 Shared Task: Detecting Emotions in Reaction to News Stories Using Transformers and Stacked Embeddings
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Vivek Kumar, Prayag Tiwari, Sushmita Singh</h5>
            <p class="card-text">Our system, VISU, participated in the WASSA 2023 Shared Task (3) of Emotion Classification from essays written in reaction to news articles. Emotion detection from complex dialogues is challenging and often requires context/domain understanding. Therefore in this research, we have focused on developing deep learning (DL) models using the combination of word embedding representations with tailored prepossessing strategies to capture the nuances of emotions expressed. Our experiments used static and contextual embeddings (individual and stacked) with Bidirectional Long short-term memory (BiLSTM) and Transformer based models. We occupied rank tenth in the emotion detection task by scoring a Macro F1-Score of 0.2717, validating the efficacy of our implemented approaches for small and imbalanced datasets with mixed categories of target emotions.</p>
            <a href="/paper_WASSA_112.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Emotion and Sentiment Guided Paraphrasing
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Justin Xie, Ameeta Agrawal</h5>
            <p class="card-text">Paraphrase generation, a.k.a. paraphrasing, is a common and important task in natural language processing. Emotional paraphrasing, which changes the emotion embodied in a piece of text while preserving its meaning, has many potential applications, including moderating online dialogues and preventing cyberbullying. We introduce a new task of fine-grained emotional paraphrasing along emotion gradients, that is, altering the emotional intensities of the paraphrases in fine-grained settings following smooth variations in affective dimensions while preserving the meaning of the original text. We reconstruct several widely used paraphrasing datasets by augmenting the input and target texts with their fine-grained emotion labels. Then, we propose a framework for emotion and sentiment guided paraphrasing by leveraging pre-trained language models for conditioned text generation. Extensive evaluation of the fine-tuned models suggests that including fine-grained emotion labels in the paraphrase task significantly improves the likelihood of obtaining high-quality paraphrases that reflect the desired emotions while achieving consistently better scores in paraphrase metrics such as BLEU, ROUGE, and METEOR.  
</p>
            <a href="/paper_WASSA_15.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Emotions in Spoken Language - Do we need acoustics?
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Nadine Probol, Margot Mieskes</h5>
            <p class="card-text">Work on emotion detection is often focused on textual data from i.e. Social Media. If multimodal data (i.e. speech) is analysed, the focus again is often placed on the transcription. This paper takes a closer look at how crucial acoustic information actually is for the recognition of emotions from multimodal data. To this end we use the IEMOCAP data, which is one of the larger data sets that provides transcriptions, audio recordings and manual emotion categorization. We build models for emotion classification using text-only, acoustics-only and combining both modalities in order to examine the influence of the various modalities on the final categorization. Our results indicate that using text-only models outperform acoustics-only models. But combining text-only and acoustic-only models improves the results. Additionally, we perform a qualitative analysis and find that a range of misclassifications are due to factors not related to the model, but to the data such as, recording quality, a challenging classification task and misclassifications that are unsurprising for humans.</p>
            <a href="/paper_WASSA_16.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Understanding Emotion Valence is a Joint Deep Learning Task
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Gabriel Roccabruna, Seyed Mahed Mousavi, Giuseppe Riccardi</h5>
            <p class="card-text">The valence analysis of speakers&#39; utterances or written posts helps to understand the activation and variations of the emotional state throughout the conversation. More recently, the concept of Emotion Carriers (EC) has been introduced to explain the emotion felt by the speaker and its manifestations. In this work, we investigate the natural inter-dependency of valence and ECs via a multi-task learning approach. We experiment with Pre-trained Language Models (PLM) for single-task, two-step, and joint settings for the valence and EC prediction tasks. We compare and evaluate the performance of generative (GPT-2) and discriminative (BERT) architectures in each setting. We observed that providing the ground truth label of one task improves the prediction performance of the models in the other task. We further observed that the discriminative model achieves the best trade-off of valence and EC prediction tasks in the joint prediction setting. As a result, we attain a single model that performs both tasks, thus, saving computation resources at training and inference times.</p>
            <a href="/paper_WASSA_17.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Czech-ing the News: Article Trustworthiness Dataset for Czech
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Matyas Bohacek, Michal Bravansky, Filip Trhlík, Vaclav Moravec</h5>
            <p class="card-text">We present the Verifee dataset: a multimodal dataset of news articles with fine-grained trustworthiness annotations. We bring a diverse set of researchers from social, media, and computer sciences aboard to study this interdisciplinary problem holistically and develop a detailed methodology that assesses the texts through the lens of editorial transparency, journalist conventions, and objective reporting while penalizing manipulative techniques. We collect over $10,000$ annotated articles from $60$ Czech online news sources. Each item is categorized into one of the $4$ proposed classes on the credibility spectrum -- ranging from entirely trustworthy articles to deceptive ones -- and annotated of its manipulative attributes. We fine-tune prominent sequence-to-sequence language models for the trustworthiness classification task on our dataset and report the best F-1 score of $0.53$. We open-source the dataset, annotation methodology, and annotators&#39; instructions in full length at https://www.verifee.ai/research/ to enable easy build-up work.</p>
            <a href="/paper_WASSA_18.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Findings of WASSA 2023 Shared Task: Multi-Label and Multi-Class Emotion Classification on Code-Mixed Text Messages
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Iqra Ameer, Necva Bölücü, Hua Xu, Ali Al Bataineh</h5>
            <p class="card-text">We present the results of the WASSA 2023 Shared-Task 2: Emotion Classification on code-mixed text messages (Roman Urdu + English), which included two tracks for emotion classification: multi-label and multi-class. The participants were provided with a dataset of code-mixed SMS messages in English and Roman Urdu labeled with 12 emotions for both tracks. A total of 5 teams (19 team members) participated in the shared task. We summarized the methods, resources, and tools used by the participating teams. We also made the data freely available for further improvements to the task.</p>
            <a href="/paper_WASSA_201.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Emotion classification on code-mixed text messages via soft prompt tuning
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Jinghui Zhang, Dongming Yang, Siyu Bao, Lina Cao, Shunguo Fan</h5>
            <p class="card-text">Emotion classification on code-mixed text messages is challenging due to the multilingual languages and non-literal cues (i.e., emoticons). To solve these problems,  we propose an innovative soft prompt tuning method, which is lightweight and effective to release potential abilities of the pre-trained language models and improve the classification results. Firstly, we transform emoticons into textual information to utilize their rich emotional information. Then, variety of innovative templates and verbalizers are applied to promote emotion classification. Extensive experiments show that transforming emoticons and employing prompt tuning both benefit the performance. Finally, as a part of WASSA 2023, we obtain the accuracy of 0.972 in track MLEC and 0.892 in track MCEC, yielding the second place in both two tracks.</p>
            <a href="/paper_WASSA_202.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            PrecogIIITH@WASSA2023: Emotion Detection for Urdu-English Code-mixed Text
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Bhaskara Hanuma Vedula, Prashant Kodali, Manish Shrivastava, Ponnurangam Kumaraguru</h5>
            <p class="card-text">Code-mixing refers to the phenomenon of using two or more languages interchangeably within a speech or discourse context. This practice is particularly prevalent on social media platforms, and determining the embedded affects in a code-mixed sentence remains as a challenging problem. In this submission we describe our system for WASSA 2023 Shared Task on Emotion Detection in English-Urdu code-mixed text. In our system we implement a multiclass emotion detection model with label space of 11 emotions. Samples are code-mixed English-Urdu text, where Urdu is written in romanised form. Our submission is limited to one of the subtasks - Multi Class classification and we leverage transformer-based Multilingual Large Language Models (MLLMs), XLM-RoBERTa and Indic-BERT. We fine-tune MLLMs on the released data splits, with and without pre-processing steps (translation to english), for classifying texts into the appropriate emotion category. Our methods did not surpass the baseline, and our submission is ranked sixth overall.</p>
            <a href="/paper_WASSA_203.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            BpHigh at WASSA 2023: Using Contrastive Learning to build Sentence Transformer models for Multi-Class Emotion Classification in Code-mixed Urdu
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Bhavish Pahwa</h5>
            <p class="card-text">In this era of digital communication and social media, texting and chatting among individuals occur mainly through code-mixed or Romanized versions of the native language prevalent in the region. The presence of Romanized and code-mixed language develops the need to build NLP systems in these domains to leverage the digital content for various use cases. This paper describes our contribution to the subtask MCEC of the shared task WASSA 2023:Shared Task on Multi-Label and Multi-Class Emotion Classification on Code-Mixed Text Messages. We explore how one can build sentence transformers models for low-resource languages using unsupervised data by leveraging contrastive learning techniques described in the SIMCSE paper and using the sentence transformer developed to build classification models using the SetFit approach. Additionally, we&#39;ll publish our code and models on GitHub and HuggingFace, two open-source hosting services.</p>
            <a href="/paper_WASSA_204.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            YNU-HPCC at WASSA 2023: Using Text-Mixed Data Augmentation for Emotion Classification on Code-Mixed Text Message
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Xuqiao Ran, You Zhang, Jin Wang, Dan Xu, Xuejie Zhang</h5>
            <p class="card-text">Emotion classification on code-mixed texts has been widely used in real-world applications. In this paper, we build a system that participates in the WASSA 2023 Shared Task 2 for emotion classification on code-mixed text messages from Roman Urdu and English. The main goal of the proposed method is to adopt a text-mixed data augmentation for robust code-mixed text representation. We mix texts with both multi-label (track 1) and multi-class (track 2) annotations in a unified multilingual pre-trained model, i.e., XLM-RoBERTa, for both subtasks. Our results show that the proposed text-mixed method performs competitively, ranking first in both tracks, achieving an average Macro F1 score of 0.9782 on the multi-label track and of 0.9329 on the multi-class track.</p>
            <a href="/paper_WASSA_205.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Generative Pretrained Transformers for Emotion Detection in a Code-Switching Setting
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Andrew Nedilko</h5>
            <p class="card-text">This paper describes the approach that we utilized to participate in the shared task for multi-label and multi-class emotion classification organized as part of WASSA 2023 at ACL 2023. The objective was to build mod- els that can predict 11 classes of emotions, or the lack thereof (neutral class) based on code- mixed Roman Urdu and English SMS text messages. We participated in Track 2 of this task - multi-class emotion classification (MCEC). We used generative pretrained transformers, namely ChatGPT because it has a commercially available full-scale API, for the emotion detec- tion task by leveraging the prompt engineer- ing and zero-shot / few-shot learning method- ologies based on multiple experiments on the dev set. Although this was the first time we used a GPT model for the purpose, this ap- proach allowed us to beat our own baseline character-based XGBClassifier, as well as the baseline model trained by the organizers (bert- base-multilingual-cased). We ranked 4th and achieved the macro F1 score of 0.7038 and the accuracy of 0.7313 on the blind test set.</p>
            <a href="/paper_WASSA_206.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Towards Detecting Harmful Agendas in News Articles
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Melanie Subbiah, Amrita Bhattacharjee, Yilun Hua, Tharindu Kumarage, Huan Liu, Kathleen McKeown</h5>
            <p class="card-text">Manipulated news online is a growing problem which necessitates the use of automated systems to curtail its spread. We argue that while misinformation and disinformation detection have been studied, there has been a lack of investment in the important open challenge of detecting harmful agendas in news articles; identifying harmful agendas is critical to flag news campaigns with the greatest potential for real world harm. Moreover, due to real concerns around censorship, harmful agenda detectors must be interpretable to be effective. In this work, we propose this new task and release a dataset, \textsc{NewsAgendas}, of annotated news articles for agenda identification. We show how interpretable systems can be effective on this task and demonstrate that they can perform comparably to black-box models.</p>
            <a href="/paper_WASSA_21.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            GSAC: A Gujarati Sentiment Analysis Corpus from Twitter
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Monil Gokani, Radhika Mamidi</h5>
            <p class="card-text">Sentiment Analysis is an important task for analysing online content across languages for tasks such as content moderation and opinion mining. Though a significant amount of resources are available for Sentiment Analysis in several Indian languages, there do not exist any large-scale, open-access corpora for Gujarati. Our paper presents and describes the Gujarati Sentiment Analysis Corpus (GSAC), which has been sourced from Twitter and manually annotated by native speakers of the language. We describe in detail our collection and annotation processes and conduct extensive experiments on our corpus to provide reliable baselines for future work using our dataset.</p>
            <a href="/paper_WASSA_22.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            A Dataset for Explainable Sentiment Analysis in the German Automotive Industry
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Andrea Zielinski, Calvin Spolwind, Henning Kroll, Anna Grimm</h5>
            <p class="card-text">While deep learning models have greatly improved the performance of many tasks related to sentiment analysis and classification, they are often criticized for being untrustworthy due to their black-box nature. As a result, numerous explainability techniques have been proposed to better understand the model predictions and to improve the deep learning models. 
In this work, we introduce InfoBarometer, the first benchmark for examining interpretable methods related to sentiment analysis in the German automotive sector based on online news. Each news article in our dataset is annotated w.r.t. overall sentiment (i.e., positive, negative and neutral), the target of the sentiment (focusing on innovation-related topics such as e.g. electromobility) and the rationales, i.e., textual explanations for the sentiment label  that can be leveraged during both training and evaluation.
For this research, we compare different state-of-the-art approaches to perform sentiment analysis and observe that even models that perform very well in classification do not score high on explainability metrics like model plausibility and faithfulness. 
We calculated the polarity scores for the best method BERT and got an F-score of 73.6.  
Moreover, we evaluated different interpretability algorithms (LIME, SHAP, Integrated Gradients, Saliency) based on explicitly marked rationales by human annotators quantitatively and qualitatively.
Our experiments demonstrate that the textual explanations often do not agree with human interpretations, and rarely help to justify the models decision. However, local and global features provide useful insights to help  uncover spurious features in the model and biases within the dataset. We intend to make our dataset public for other researchers</p>
            <a href="/paper_WASSA_23.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Examining Bias in Opinion Summarisation through the Perspective of Opinion Diversity
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Nannan Huang, Lin Tian, Haytham Fayek, Xiuzhen Zhang</h5>
            <p class="card-text">Opinion summarisation is a task that aims to condense the information presented in the source documents while retaining the core message and opinions. A summary that only represents the majority opinions will leave the minority opinions unrepresented in the summary. In this paper, we use the stance towards a certain target as an opinion. We study bias in opinion summarisation from the perspective of opinion diversity, which measures whether the model generated summary can cover a diverse set of opinions. In addition, we examine opinion similarity, a measure of how closely related two opinions are in terms of their stance on a given topic, and its relationship with opinion diversity. Through the lense of stances towards a topic, we examine opinion diversity and similarity using three debatable topics under COVID-19. Experimental results on these topics revealed that a higher degree of similarity of opinions did not indicate good diversity or fairly cover the various opinions originally presented in the source documents. We found that BART and ChatGPT can better capture diverse opinions presented in the source documents.</p>
            <a href="/paper_WASSA_24.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Fluency Matters! Controllable Style Transfer with Syntax Guidance
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Ji-Eun Han, Kyung-Ah Sohn</h5>
            <p class="card-text">Unsupervised text style transfer is a challenging task that aims to alter the stylistic attributes of a given text without affecting its original content. One of the methods to achieve this is controllable style transfer, which allows for the control of the degree of style transfer. However, an issue encountered with controllable style transfer is the instability of transferred text fluency when the degree of the style transfer changes. To address this problem, we propose a novel approach that incorporates additional syntax parsing information during style transfer. By leveraging the syntactic information, our model is guided to generate natural sentences that effectively reflect the desired style while maintaining fluency. Experimental results show that our method achieves robust performance and improved fluency compared to previous controllable style transfer methods.</p>
            <a href="/paper_WASSA_27.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            ChatGPT for Suicide Risk Assessment on Social Media: Quantitative Evaluation of Model Performance, Potentials and Limitations
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Hamideh Ghanadian, Isar Nejadgholi, Hussein Al Osman</h5>
            <p class="card-text">This paper presents a novel framework for quantitatively evaluating the interactive ChatGPT model in the context of  suicidality assessment from social media posts, utilizing the University of Maryland Reddit suicidality dataset. We conduct a technical evaluation of ChatGPT&#39;s performance on this task using Zero-Shot and Few-Shot experiments and compare its results with those of two fine-tuned transformer-based models. Additionally, we investigate the impact of different temperature parameters on ChatGPT&#39;s response generation and discuss the optimal temperature based on the inconclusiveness rate of ChatGPT. Our results indicate that while ChatGPT attains considerable accuracy in this task, transformer-based models fine-tuned on human-annotated datasets exhibit superior performance. Moreover, our  analysis sheds light on how adjusting the ChatGPT&#39;s hyperparameters can improve its ability to assist mental health professionals in this critical task. </p>
            <a href="/paper_WASSA_28.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Unsupervised Domain Adaptation using Lexical Transformations and Label Injection for Twitter Data
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Akshat Gupta, Xiaomo Liu, Sameena Shah</h5>
            <p class="card-text">Domain adaptation is an important and widely studied problem in natural language processing. A large body of literature tries to solve this problem by adapting models trained on the source domain to the target domain. In this paper, we instead solve this problem from a dataset perspective. We modify the source domain dataset with simple lexical transformations to reduce the domain shift between the source dataset distribution and the target dataset distribution. We find that models trained on the transformed source domain dataset performs significantly better than zero-shot models. Using our proposed transformations to convert standard English to tweets, we reach an unsupervised part-of-speech (POS) tagging accuracy of 92.14% (from 81.54% zero shot accuracy), which is only slightly below the supervised performance of 94.45%. We also use our proposed transformations to synthetically generate tweets and augment the Twitter dataset to achieve state-of-the-art performance for POS tagging.</p>
            <a href="/paper_WASSA_29.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Transformer-based cynical expression detection in a corpus of Spanish YouTube reviews
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Samuel Gonzalez-Lopez, Steven Bethard</h5>
            <p class="card-text">Consumers of services and products exhibit a wide range of behaviors on social networks when they are dissatisfied. In this paper, we consider three types of cynical expressions negative feelings, specific reasons, and attitude of being right and annotate a corpus of 3189 comments in Spanish on car analysis channels from YouTube. We evaluate both token classification and text classification settings for this problem, and compare performance of different pre-trained models including BETO, SpanBERTa, Multilingual Bert, and RoBERTuito. The results show that models achieve performance above 0.8 F1 for all types of cynical expressions in the text classification setting, but achieve lower performance (around 0.6-0.7 F1) for the harder token classification setting.</p>
            <a href="/paper_WASSA_30.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Multilingual Language Models are not Multicultural: A Case Study in Emotion
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Shreya Havaldar, Bhumika Singhal, Sunny Rai, Langchen Liu, Sharath Chandra Guntuku, Lyle Ungar</h5>
            <p class="card-text">Emotions are experienced and expressed differently across the world. In order to use Large Language Models (LMs) for multilingual tasks that require emotional sensitivity, LMs must reflect this cultural variation in emotion. In this study, we investigate whether the widely-used multilingual LMs in 2023 reflect differences in emotional expressions across cultures and languages. We find that embeddings obtained from LMs (e.g., XLM-RoBERTa) are Anglocentric, and generative LMs (e.g., ChatGPT) reflect Western norms, even when responding to prompts in other languages. Our results show that multilingual LMs do not successfully learn the culturally appropriate nuances of emotion and we highlight possible research directions towards correcting this.</p>
            <a href="/paper_WASSA_31.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Painsight: An Extendable Opinion Mining Framework for Detecting Pain Points Based on Online Customer Reviews
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Yukyung Lee, Jaehee Kim, Doyoon Kim, Yookyung Kho, Younsun Kim, Pilsung Kang</h5>
            <p class="card-text">As the e-commerce market continues to expand and online transactions proliferate, customer reviews have emerged as a critical element in shaping the purchasing decisions of prospective buyers. Previous studies have endeavored to identify key aspects of customer reviews through the development of sentiment analysis models and topic models. However, extracting specific dissatisfaction factors remains a challenging task. In this study, we delineate the pain point detection problem and propose Painsight, an unsupervised framework for automatically extracting distinct dissatisfaction factors from customer reviews without relying on ground truth labels. Painsight employs pre-trained language models to construct sentiment analysis and topic models, leveraging attribution scores derived from model gradients to extract dissatisfaction factors. Upon application of the proposed methodology to customer review data spanning five product categories, we successfully identified and categorized dissatisfaction factors within each group, as well as isolated factors for each type. Notably, Painsight outperformed benchmark methods, achieving substantial performance enhancements and exceptional results in human evaluations.</p>
            <a href="/paper_WASSA_32.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Context-Dependent Embedding Utterance Representations for Emotion Recognition in Conversations
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Patrícia Pereira, Helena Moniz, Isabel Dias, Joao Paulo Carvalho</h5>
            <p class="card-text">Emotion Recognition in Conversations (ERC) has been gaining increasing importance as conversational agents become more and more common. Recognizing emotions is key for effective communication, being a crucial component in the development of effective and empathetic conversational agents. Knowledge and understanding of the conversational context are extremely valuable for identifying the emotions of the interlocutor. We thus approach Emotion Recognition in Conversations leveraging the conversational context, i.e., taking into attention previous conversational turns. The usual approach to model the conversational context has been to produce context-independent representations of each utterance and subsequently perform contextual modeling of these. Here we propose context-dependent embedding representations of each utterance by leveraging the contextual representational power of pre-trained transformer language models. In our approach, we feed the conversational context appended to the utterance to be classified as input to the RoBERTa encoder, to which we append a simple classification module, thus discarding the need to deal with context after obtaining the embeddings since these constitute already an efficient representation of such context. We also investigate how the number of introduced conversational turns influences our model performance. The effectiveness of our approach is validated on the open-domain DailyDialog dataset and on the task-oriented EmoWOZ dataset.
</p>
            <a href="/paper_WASSA_33.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Combining Active Learning and Task Adaptation with BERT for Cost-Effective Annotation of Social Media Datasets
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Jens Lemmens, Walter Daelemans</h5>
            <p class="card-text">Social media provide a rich source of data that can be mined and used for a wide variety of research purposes. However, annotating this data can be expensive, yet necessary for state-of-the-art pre-trained language models to achieve high prediction performance. Therefore, we combine pool-based active learning based on prediction uncertainty (an established method for reducing annotation costs) with unsupervised task adaptation through Masked Language Modeling (MLM). The results on three different datasets (two social media corpora, one benchmark dataset) show that task adaptation significantly improves results and that with only a fraction of the available training data, this approach reaches similar F1-scores as those achieved by an upper-bound baseline model fine-tuned on all training data. We hereby contribute to the scarce corpus of research on active learning with pre-trained language models and propose a cost-efficient annotation sampling and fine-tuning approach that can be applied to a wide variety of tasks and datasets.</p>
            <a href="/paper_WASSA_34.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Improving Dutch Vaccine Hesitancy Monitoring via Multi-Label Data Augmentation with GPT-3.5
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Jens Van Nooten, Walter Daelemans</h5>
            <p class="card-text">In this paper, we leverage the GPT-3.5 language model both using the Chat-GPT API interface and the GPT-3.5 API interface to generate realistic examples of anti-vaccination tweets in Dutch with the aim of augmenting an imbalanced multi-label vaccine hesitancy argumentation classification dataset. In line with previous research, we devise a prompt that, on the one hand, instructs the model to generate realistic examples based on the gold standard dataset and, on the other hand, to assign multiple pseudo-labels (or a single pseudo-label) to the generated instances. We then augment our gold standard data with the generated examples and evaluate the impact thereof in a cross-validation setting with several state-of-the-art Dutch large language models. This augmentation technique predominantly shows improvements in F1 for classifying underrepresented classes while increasing the overall recall, paired with a slight decrease in precision for more common classes. Furthermore, we examine how well the synthetic data generalises to human data in the classification task. To our knowledge, we are the first to utilise Chat-GPT and GPT-3.5 for augmenting a Dutch multi-label dataset classification task.</p>
            <a href="/paper_WASSA_35.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Emotion Analysis of Tweets Banning Education in Afghanistan
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Mohammad Ali Hussiny, Lilja Øvrelid</h5>
            <p class="card-text">This paper introduces the first emotion-annotated dataset for the Dari variant of Persian spoken in Afghanistan. The LetHerLearn dataset contains 7,600 tweets posted in reaction to the Taliban&#39;s ban of women&#39;s rights to education in 2022 and has been manually annotated according to Ekman&#39;s emotion categories. We here detail the data collection and annotation process, present relevant dataset statistics as well as initial experiments on the resulting dataset, benchmarking a number of different neural architectures for the task of Dari emotion classification. </p>
            <a href="/paper_WASSA_37.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Identifying Slurs and Lexical Hate Speech via Light-Weight Dimension Projection in Embedding Space
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Sanne Hoeken, Sina Zarrieß, Ozge Alacam</h5>
            <p class="card-text">The prevalence of hate speech on online platforms has become a pressing concern for society, leading to increased attention towards detecting hate speech. Prior work in this area has primarily focused on identifying hate speech at the utterance level that reflects the complex nature of hate speech. In this paper, we propose a targeted and efficient approach to identifying hate speech by detecting slurs at the lexical level using contextualized word embeddings. We hypothesize that slurs have a systematically different representation than their neutral counterparts, making them identifiable through existing methods for discovering semantic dimensions in word embeddings. The results demonstrate the effectiveness of our approach in predicting slurs, confirming linguistic theory that the meaning of slurs is stable across contexts. Our robust hate dimension approach for slur identification offers a promising solution to tackle a smaller yet crucial piece of the complex puzzle of hate speech detection.</p>
            <a href="/paper_WASSA_38.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Sentiment and Emotion Classification in Low-resource Settings
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Jeremy Barnes</h5>
            <p class="card-text">The popularity of sentiment and emotion analysis has lead to an explosion of datasets, approaches, and papers. However, these are often tested in optimal settings, where plentiful training and development data are available, and compared mainly with recent state-of-the-art models that have been similarly evaluated. 

In this paper, we instead present a systematic comparison of sentiment and emotion classification methods, ranging from rule- and dictionary-based methods to recently proposed few-shot and prompting methods with large language models. We test these methods in-domain, out-of-domain, and in cross-lingual settings and find that in low-resource settings, rule- and dictionary-based methods perform as well or better than few-shot and prompting methods, especially for emotion classification. Zero-shot cross-lingual approaches, however, still outperform in-language dictionary induction.
</p>
            <a href="/paper_WASSA_39.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Sentimental Matters - Predicting Literary Quality by Sentiment Analysis and Stylometric Features
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Yuri Bizzoni, Pascale Moreira, Mads Rosendahl Thomsen, Kristoffer Nielbo</h5>
            <p class="card-text">Over the years, the task of predicting reader appreciation or literary quality has been the object of several studies, but it remains a challenging problem in quantitative literary studies and computational linguistics alike, as its definition can vary a lot depending on the genre, the adopted features and the annotation system. This paper attempts to evaluate the impact of sentiment arc modelling versus more classical stylometric features for user-ratings of novels. We run our experiments on a corpus of English language narrative literary fiction from the 19th and 20th century, showing that syntactic and surface-level features can be powerful for the study of literary quality, but can be outperformed by sentiment-characteristics of a text. </p>
            <a href="/paper_WASSA_4.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Analyzing Subjectivity Using a Transformer-Based Regressor Trained on Naïve Speakers’ Judgements
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Elena Savinova, Fermin Moscoso Del Prado</h5>
            <p class="card-text">The problem of subjectivity detection is often approached as a preparatory binary task for sentiment analysis, despite the fact that theoretically subjectivity is often defined as a matter of degree. In this work, we approach subjectivity analysis as a regression task and test the efficiency of a transformer RoBERTa model in annotating subjectivity of online news, including news from social media, based on a small subset of human-labeled training data. The results of experiments comparing our model to an existing rule-based subjectivity regressor and a state-of-the-art binary classifier reveal that: 1) our model highly correlates with the human subjectivity ratings and outperforms the widely used rule-based &#34;pattern&#34; subjectivity regressor (De Smedt and Daelemans, 2012); 2) our model performs well as a binary classifier and generalizes to the benchmark subjectivity dataset (Pang and Lee, 2004); 3) in contrast, state-of-the-art classifiers trained on the benchmark dataset show catastrophic performance on our human-labeled data. The results bring to light the issues of the gold standard subjectivity dataset, and the models trained on it, which seem to distinguish between the origin/style of the texts rather than subjectivity as perceived by human English speakers.</p>
            <a href="/paper_WASSA_40.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            A Fine Line Between Irony and Sincerity: Identifying Bias in Transformer Models for Irony Detection
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Aaron Maladry, Els Lefever, Cynthia Van Hee, Veronique Hoste</h5>
            <p class="card-text">In this paper we investigate potential bias in fine-tuned transformer models for irony detection. Bias is defined in this research as spurious associations between word n-grams and class labels, that can cause the system to rely too much on superficial cues and miss the essence of the irony. For this purpose, we looked for correlations between class labels and words that are prone to trigger irony, such as positive adjectives, intensifiers and topical nouns. Additionally, we investigate our irony model’s predictions before and after manipulating the data set through irony trigger replacements. We further support these insights with state-of-the-art explainability techniques (Layer Integrated Gradients, Discretized Integrated Gradients and Layer-wise Relevance Propagation). Both approaches confirm the hypothesis that transformer models generally encode correlations between positive sentiments and ironic texts, with even higher correlations between vividly expressed sentiment and irony. Based on these insights, we implemented a number of modification strategies to enhance the robustness of our irony classifier.</p>
            <a href="/paper_WASSA_41.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            ChatGPT is fun, but it is not funny! Humor is still challenging Large Language Models
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Sophie Jentzsch, Kristian Kersting</h5>
            <p class="card-text">Humor is a central aspect of human communication that has not been solved for artificial agents so far. Large language models (LLMs) are increasingly able to capture implicit and contextual information. Especially, OpenAI’s ChatGPT recently gained immense public attention. The GPT3-based model almost seems to communicate on a human level and can even tell jokes. Humor is an essential component of human communication. But is ChatGPT really funny?

We put ChatGPT’s sense of humor to the test. In a series of exploratory experiments around jokes, i.e., generation, explanation, and detection, we seek to understand ChatGPT’s capability to grasp and reproduce human humor. Since the model itself is not accessible, we applied prompt-based experiments. 

Our empirical evidence indicates that jokes are not hard-coded but mostly also not newly generated by the model. Over 90% of 1008 generated jokes were the same 25 Jokes. The system accurately explains valid jokes but also comes up with fictional explanations for invalid jokes. Joke-typical characteristics can mislead ChatGPT in the classification of jokes. ChatGPT has not solved computational humor yet but it can be a big leap toward “funny” machines.</p>
            <a href="/paper_WASSA_43.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            How to Control Sentiment in Text Generation: A Survey of the State-of-the-Art in Sentiment-Control Techniques
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Michela Lorandi, Anya Belz</h5>
            <p class="card-text">Recent advances in the development of large Pretrained Language Models, such as GPT, BERT and Bloom, have achieved remarkable performance on a wide range of different NLP tasks. However, when used for text generation tasks, these models still have limitations when it comes to controlling the content and style of the generated text, often producing content that is incorrect, irrelevant, or inappropriate in the context of a given task. In this survey paper, we explore methods for controllable text generation with a focus on sentiment control. We systematically collect papers from the ACL Anthology, create a categorisation scheme based on different control techniques and controlled attributes, and use the scheme to categorise and compare methods. The result is a detailed and comprehensive overview of state-of-the-art techniques for sentiment-controlled text generation categorised on the basis of how the control is implemented and what attributes are controlled and providing a clear idea of their relative strengths and weaknesses.</p>
            <a href="/paper_WASSA_44.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Transformer-based Prediction of Emotional Reactions to Online Social Network Posts
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Irene Benedetto, Moreno La Quatra, Luca Cagliero, Luca Vassio, Martino Trevisan</h5>
            <p class="card-text">Emotional reactions to Online Social Network posts have recently gained importance in the study of the online ecosystem. Prior to post publication, the number of received reactions can be predicted based on either the textual content of the post or the related metadata. However, existing approaches suffer from both the lack of semantic-aware language understanding models and the limited explainability of the prediction models. To overcome these issues, we present a new transformer-based method to predict the number of emotional reactions of different types to social posts. It leverages the attention mechanism to capture arbitrary semantic textual relations neglected by prior works. Furthermore, it also provides end-users with textual explanations of the predictions. The results achieved on a large collection of Facebook posts confirm the applicability of the presented methodology. </p>
            <a href="/paper_WASSA_45.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Transfer Learning for Code-Mixed Data: Do Pretraining Languages Matter?
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Kushal Tatariya, Heather Lent, Miryam De Lhoneux</h5>
            <p class="card-text">Monolinguals make up a minority of the world&#39;s speakers, and yet most language technologies lag behind in handling linguistic behaviours produced by bilingual and multilingual speakers. A commonly observed phenomenon in such communities is code-mixing, which is prevalent on social media, and thus requires attention in NLP research. In this work, we look into the ability of pretrained language models to handle code-mixed data, with a focus on the impact of languages present in pretraining on the downstream performance of the model as measured on the task of sentiment analysis. Ultimately, we find that the pretraining language has little effect on performance when the model sees code-mixed data during downstream finetuning. We also evaluate the models on code-mixed data in a zero-shot setting, after task-specific finetuning on a monolingual dataset. We find that this brings out differences in model performance that can be attributed to the pretraining languages. We present a thorough analysis of these findings that also looks at model performance based on the composition of participating languages in the code-mixed datasets. </p>
            <a href="/paper_WASSA_48.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Can ChatGPT Understand Causal Language in Science Claims?
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Yuheun Kim, Lu Guo, Bei Yu, Yingya Li</h5>
            <p class="card-text">This study evaluated ChatGPT&#39;s ability to understand causal language in science papers and news by testing its accuracy in a task of labeling the strength of a claim as causal, conditional causal,  correlational, or no relationship. The results show that ChatGPT is still behind the existing fine-tuned BERT models by a large margin. ChatGPT also had difficulty understanding conditional causal claims mitigated by hedges. However, its weakness may be utilized to improve the clarity of human annotation guideline. Chain-of-Thoughts were faithful and helpful for improving prompt performance, but finding the optimal prompt is difficult with inconsistent results and the lack of effective method to establish cause-effect between prompts and outcomes, suggesting caution when generalizing prompt engineering results across tasks or models.
</p>
            <a href="/paper_WASSA_51.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Systematic Evaluation of GPT-3 for Zero-Shot Personality Estimation
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Adithya V Ganesan, Yash Kumar Lal, August Nilsson, H. Schwartz</h5>
            <p class="card-text">Very large language models (LLMs) perform extremely well on a spectrum of NLP tasks in a zero-shot setting. However, little is known about their performance on human-level NLP problems which rely on understanding psychological concepts, such as assessing personality traits. In this work, we investigate the zero-shot ability of GPT-3 to estimate the Big 5 personality traits from users&#39; social media posts. Through a set of systematic experiments, we find that zero-shot GPT-3 performance is somewhat close to an existing pre-trained SotA for broad classification upon injecting knowledge about the trait in the prompts. However, when prompted to provide fine-grained classification, its performance drops to close to a simple most frequent class (MFC) baseline. We further analyze where GPT-3 performs better, as well as worse, than a pretrained lexical model, illustrating systematic errors that suggest ways to improve LLMs on human-level NLP tasks. The code for this project is available on Github.</p>
            <a href="/paper_WASSA_52.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Utterance Emotion Dynamics in Children&#39;s Poems: Emotional Changes Across Age
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Daniela Teodorescu, Alona Fyshe, Saif Mohammad</h5>
            <p class="card-text">Emerging psychopathology studies are showing that patterns of changes in emotional state --- emotion dynamics --- are associated with overall well-being and mental health. More recently, there has been some work in tracking emotion dynamics through one&#39;s utterances, allowing for data to be collected on a larger scale across time and people. However, several questions about how emotion dynamics change with age, especially in children, and when determined through children&#39;s writing, remain unanswered. In this work, we use both a lexicon and a machine learning based approach to quantify characteristics of emotion dynamics determined from poems written by children of various ages. We show that both approaches point to similar trends: consistent increasing intensities for some emotions (e.g., anger, fear, joy, sadness, arousal, and dominance) with age and a consistent decreasing valence with age. We also find increasing emotional variability, rise rates (i.e., emotional reactivity), and recovery rates (i.e., emotional regulation) with age. These results act as a useful baselines for further research in how patterns of emotions expressed by children change with age, and their association with mental health.</p>
            <a href="/paper_WASSA_55.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Annotating and Training for Population Subjective Views
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Maria Alexeeva, Caroline Hyland, Keith Alcock, Allegra A. Beal Cohen, Hubert Kanyamahanga, Isaac Kobby Anni, Mihai Surdeanu</h5>
            <p class="card-text">In this paper, we present a dataset of subjective views (beliefs and attitudes) held by individuals or groups. We analyze the usefulness of the dataset by training a neural classifier that identifies belief-containing sentences that are relevant for our broader project of interest---scientific modeling of complex systems. We also explore and discuss difficulties related to annotation of subjective views  and propose ways of addressing them.</p>
            <a href="/paper_WASSA_57.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Exploration of Contrastive Learning Strategies toward more Robust Stance Detection
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Udhaya Kumar Rajendran, Amine Trabelsi</h5>
            <p class="card-text">Stance Detection is the task of identifying the position of an author of a text towards an issue or a target. Previous studies on Stance Detection indicate that the existing systems are non-robust to the variations and errors in input sentences. Our proposed methodology uses Contrastive Learning to learn sentence representations by bringing semantically similar sentences and sentences implying the same stance closer to each other in the embedding space. We compare our approach to a pretrained transformer model directly finetuned with the stance datasets. We use char-level and word-level adversarial perturbation attacks to measure the resilience of the models and we show that our approach achieves better performances and is more robust to the different adversarial perturbations introduced to the test data. The results indicate that our approach performs better on small-sized and class-imbalanced stance datasets.</p>
            <a href="/paper_WASSA_60.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Adapting Emotion Detection to Analyze Influence Campaigns on Social Media
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Ankita Bhaumik, Andy Bernhardt, Gregorios Katsios, Ning Sa, Tomek Strzalkowski</h5>
            <p class="card-text">Social media is an extremely potent tool for influencing public opinion, particularly during important events such as elections, pandemics, and national conflicts. Emotions are a crucial aspect of this influence, but detecting them accurately in the political domain is a significant challenge due to the lack of suitable emotion labels and training datasets. In this paper, we present a generalized approach to emotion detection that can be adapted to the political domain with minimal performance sacrifice. Our approach is designed to be easily integrated into existing models without the need for additional training or fine-tuning. We demonstrate the zero-shot and few-shot performance of our model on the 2017 French presidential elections and propose efficient emotion groupings that would aid in effectively analyzing influence campaigns and agendas on social media.</p>
            <a href="/paper_WASSA_61.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Not Just Iconic: Emoji Interpretation is Shaped by Use
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Brianna O&#39;Boyle, Gabriel Doyle</h5>
            <p class="card-text">Where do the meaning of emoji come from? Though it is generally assumed that emoji are fully iconic, with meanings derived from their visual forms, we argue that this is only one component of their meaning. We surveyed users and non-users of the Chinese social media platform WeChat for their interpretations of emoji specific to WeChat. We find that some emoji show significant differences in their interpretations between users and non-users, and based on how familiar a person is with the specific emoji. We argue that this reflects a more complex process for building the meaning of emoji on a platform than pure iconicity.</p>
            <a href="/paper_WASSA_62.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            The Paradox of Multilingual Emotion Detection
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Luna De Bruyne</h5>
            <p class="card-text">The dominance of English is a well-known issue in NLP research. In this position paper, I turn to state-of-the-art psychological insights to explain why this problem is especially persistent in research on automatic emotion detection, and why the seemingly promising approach of using multilingual models to include lower-resourced languages might not be the desired solution. Instead, I campaign for the use of models that acknowledge linguistic and cultural differences in emotion conceptualization and verbalization. Moreover, I see much potential in NLP to better understand emotions and emotional language use across different languages.</p>
            <a href="/paper_WASSA_65.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Sadness and Anxiety Language in Reddit Messages Before and After Quitting a Job
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Molly Ireland, Micah Iserman, Kiki Adams</h5>
            <p class="card-text">People globally quit their jobs at high rates during the COVID-19 pandemic, yet there is scant research about emotional trajectories surrounding voluntary resignations before or during that era. To explore long-term emotional language patterns before and after quitting a job, we amassed a Reddit sample of people who indicated resigning on a specific day (n = 7,436), each of whom was paired with a comparison user matched on posting history. After excluding people on the basis of low posting frequency and word count, we analyzed 150.3 million words (53.1% from 5,134 target users who indicated quitting) using SALLEE, a dictionary-based syntax-aware tool, and Linguistic Inquiry and Word Count (LIWC) dictionaries. Based on posts in the year before and after quitting, people who had quit their jobs used more sadness and anxiety language than matched comparison users. Lower rates of &#34;I&#34; pronouns and cognitive processing language were associated with less sadness and anxiety surrounding quitting. Emotional trajectories during and before the pandemic were parallel, though pandemic messages were more negative. The results have relevance for strategic self-distancing as a means of regulating negative emotions around major life changes.</p>
            <a href="/paper_WASSA_66.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Communicating Climate Change: A Comparison Between Tweets and Speeches by German Members of Parliament
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Robin Schaefer, Christoph Abels, Stephan Lewandowsky, Manfred Stede</h5>
            <p class="card-text">Twitter and parliamentary speeches are very different communication channels, but many members of parliament (MPs) make use of both. Focusing on the topic of climate change, we undertake a comparative analysis of speeches and tweets uttered by MPs in Germany in a recent six-year period. By keyword/hashtag analyses and topic modeling, we find substantial differences along party lines, with left-leaning parties discussing climate change through a crisis frame, while liberal and conservative parties try to address climate change through the lens of climate-friendly technology and practices. Only the AfD denies the need to adopt climate change mitigating measures, demeaning those concerned about a deteriorating climate as climate cult or fanatics. Our analysis reveals that climate change communication does not differ substantially between Twitter and parliamentary speeches, but across the political spectrum.</p>
            <a href="/paper_WASSA_67.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Modelling Political Aggression on Social Media Platforms
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Akash Rawat, Nazia Nafis, Dnyaneshwar Bhadane, Diptesh Kanojia, Rudra Murthy</h5>
            <p class="card-text">Recent years have seen a proliferation of aggressive social media posts, often wreaking even real-world consequences for victims. Aggressive behaviour on social media is especially evident during important sociopolitical events such as elections, communal incidents, and public protests. In this paper, we introduce a dataset in English to model political aggression. The dataset comprises public tweets collated across the time-frames of two of the most recent Indian general elections. We manually annotate this data for the task of aggression detection and analyze this data for aggressive behaviour. To benchmark the efficacy of our dataset, we perform experiments by fine-tuning pre-trained language models and comparing the results with models trained on an existing but general domain dataset. Our models consistently outperform the models trained on existing data. Our best model achieves a macro F1-score of 66.66 on our dataset. We also train models on a combined version of both datasets, achieving best macro F1-score of 92.77, on our dataset. Additionally, we create subsets of code-mixed and non-code-mixed data from the combined dataset to observe variations in results due to the Hindi-English code-mixing phenomenon. We publicly release the anonymized data, code, and models for further research.</p>
            <a href="/paper_WASSA_69.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            Instruction Tuning for Few-Shot Aspect-Based Sentiment Analysis
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Siddharth Varia, Shuai Wang, Kishaloy Halder, Robert Vacareanu, Miguel Ballesteros, Yassine Benajiba, Neha Anna John, Rishita Anubhai, Smaranda Muresan, Dan Roth</h5>
            <p class="card-text">Aspect-based Sentiment Analysis (ABSA) is a fine-grained sentiment 
analysis task which involves four elements from user-generated texts:
aspect term, aspect category, opinion term, and sentiment polarity. 
Most computational approaches focus on some of the ABSA sub-tasks
such as tuple (aspect term, sentiment polarity) or triplet (aspect term, 
opinion term, sentiment polarity) extraction using either pipeline or 
joint modeling approaches. Recently, generative approaches have 
been proposed to extract all four elements as (one or more) quadruplets
from text as a single task. In this work, we take a step further and 
propose a unified framework for solving ABSA, and the associated sub-tasks
to improve the performance in few-shot scenarios. To this end, we fine-tune 
a T5 model with instructional prompts in a multi-task learning fashion covering 
all the sub-tasks, as well as the entire quadruple prediction task. In 
experiments with multiple benchmark datasets, we show that the 
proposed multi-task prompting approach brings performance boost 
(by absolute 8.29 F1) in the few-shot learning setting.</p>
            <a href="/paper_WASSA_8.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
      <div class="col-12" style="margin-bottom: 15px;">
        <div class="card">
          <div class="card-header">
            You Are What You Read: Inferring Personality From Consumed Textual Content
          </div>
          <div class="card-body">
            <h5 class="card-title">Authors: Adam Sutton, Almog Simchon, Matthew Edwards, Stephan Lewandowsky</h5>
            <p class="card-text">In this work we use consumed text to infer Big-5 personality inventories using data we have collected from the social media platform Reddit. We test our model on two datasets, sampled from participants who consumed either fiction content ($N = 913$) or news content ($N = 213$). We show that state-of-the-art models from a similar task using authored text do not translate well to this task, with average correlations of $r=.06$ between the model&#39;s predictions and ground-truth personality inventory dimensions. We propose an alternate method of generating average personality labels for each piece of text consumed, under which our model achieves correlations as high as $r=.34$ when predicting personality from the text being read. </p>
            <a href="/paper_WASSA_9.html" class="btn btn-primary">Go to Paper</a>
          </div>
        </div>
      </div>
      
    </div>


    <script src="static/js/time-extend.js"></script>
    <script>
      $(document).ready(() => {
        add_local_tz('.session_times');
      })
    </script>

    
      </div>
    </div>
    
    

    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-9X8H03BYC2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());
      gtag("config", "G-9X8H03BYC2");
    </script>

    <!-- Footer -->
    <footer class="footer bg-light p-4">
      <div class="container">
        <p class="float-left">
          <img src="static/images/acl2023/acl-logo-2023.png" height="45px"
            width="auto" align="center">
          <span class="lead">ACL 2023</span>
        </p>
        <p class="float-right"><a href="#" class="text-dark">Back to Top</a></p>
        <p class="text-center">© 2023 Association for Computational Linguistics</p>
      </div>
    </footer>

    <!-- Code for hash tags -->
    <script type="text/javascript">
      $(document).ready(function () {
        if (location.hash !== "") {
          $('a[href="' + location.hash + '"]').tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          var hash = $(e.target).attr("href");
          if (hash.substr(0, 1) == "#") {
            var position = $(window).scrollTop();
            location.replace("#" + hash.substr(1));
            $(window).scrollTop(position);
          }
        });
      });
    </script>
    <script src="static/js/lazy_load.js"></script>
    
    <div class="modal left fade" id="chatsModal" tabindex="" role="dialog" aria-labelledby="exampleModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-dialog-scrollable" role="document" style="max-height: 100% !important;">
        <div class="modal-content" style="max-height: 100% !important;">
            <div class="modal-header">
                <h4 class="modal-title" id="exampleModalLabel">Active Chats</h4>
                <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
            </div>
            <div class="modal-body">
                <div style="margin-bottom: 1em;">
    <div class="stats-last-update text-muted" id="highly-active-chats-last-update"></div>
    <a id="highly-active-chats-btn-refresh" href="#" class="text-primary" style="display: none;">Refresh now</a>
</div>

<div id="highly-active-chats-list">
</div>

<div class="text-center" id="highly-active-chats-progress-bar" style="margin-bottom: 80em;">
    <div class="spinner-border text-primary" style="margin-top: 3em; width: 3rem; height: 3rem;" role="status">
      <span class="sr-only">Loading...</span>
    </div>
</div>

<br/>
<p class="text-muted">
    <strong>How it works: </strong>
    We calculate the number of new messages for every channel in the last N seconds. Then, we sort them descendingly.
    Channels with no new messages will be randomly shuffled. Please note that the number of messages might not be accurate.
</p>

<script src="static/js/highly-active-chats.js"></script>
<script>
    let channel_stats_server = "https://emnlp2020-channels-stats.azure-api.net"
    $(document).ready( function () {
        $('[data-toggle="tooltip"]').tooltip();
        //load_stats();
    });
</script>

            </div>

            <div class="modal-footer">
                <button type="button" class="btn btn-secondary btn-sm" data-dismiss="modal">Close</button>
            </div>
        </div>
    </div>
</div>
</body>

</html>